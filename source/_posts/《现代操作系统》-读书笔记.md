---
title: 《现代操作系统》-读书笔记
date: 2021-04-22 11:41:27
category: 操作系统
tags: [读书笔记,现代操作系统]
---



# 进程与线程

## 进程

### 进程模型

> 在进程模型中，计算机上所有可运行的软件，通常也包括操作系统，被组织成若干**顺序进程**，简称**进程**。

* 一个进程就是一个正在执行程序的实例，包括程序计数器、寄存器和变量当前值。

* 一个进程是某种类型的一个活动，它有程序、输入、输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另一个进程提供服务。



### 进程的创建

* 4种主要事件会导致进程的创建
  * 系统初始化
  * 正在运行的程序执行了创建进程的系统调用
  * 用户请求创建一个新进程
  * 一个批处理作业的初始化

* 停留在后台处理诸如电子邮件、Web页面、新闻、打印之类活动的进程称为**守护进程（daemon）**

* 在UNIX系统中，只有一个系统调用可以用来创建新进程：`fork`
  * 进程创建之后，父进程和子进程有各自不同的地址空间。修改对其他进程是不可见的。
  * 在UNIX中，子进程的初始地址空间是父进程的一个副本，不可写的内存区是共享的。或者，子进程共享父进程的所有内存，但这种情况下内存通过**写时复制**共享。
  * **可写的内存是不可以共享的**。



### 进程的终止

* 以下条件会引起一个进程的终止：
  * 正常退出（自愿）
  * 出错退出（自愿）
  * 严重错误（非自愿）
  * 被其他进程杀死（非自愿）



### 进程的层次结构

* 进程只有一个父进程。
* 在UNIX中，进程和它的所有子进程以及后裔共同组成一个进程组。



### 进程的状态

{% asset_img 进程的状态.png 进程的状态 %}

* 进程的三种状态是：
  * 运行态：该时刻进程实际占用CPU
  * 就绪态：可运行，但因为其他进程正在运行而暂时停止
  * 阻塞态：除非某种外部事件发生，否则进程不能运行



### 进程的实现

* 操作系统维护着一张表格，即进程表。每个进程占用一个进程表项。
* 该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存非配状况、所打开文件的状态、账号和调度信息吗，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。
* 与每一I/O类关联的是一个称作**中断向量**的位置。
  * 中断向量包含中断服务程序的入口地址。
  * 中断发生后操作系统最底层的工作步骤：
    1. 中断硬件将程序计数器、程序状态字等压入堆栈
    2. 硬件从中断向量装入新的程序计数器
    3. 汇编语言过程保存寄存器值
    4. 汇编语言过程设置新的堆栈
    5. C中断服务例程运行
    6. 调度程序决定下一个将运行的进程
    7. C过程返回至汇编代码
    8. 汇编语言过程开始运行新的当前进程



### 多道程序设计模型





## 线程

> 在传统的操作系统中，每个进程有一个地址空间和一个控制线程。



### 线程的使用

* 引入线程的原因
  * 需要一种并行实体拥有共享同一个地址空间和所有可用数据的能力
  * 线程比进程更轻量级，所以它们比进程更容易创建和销毁。
  * 如果存在大量的计算和大量的I/O处理，拥有多个线程允许活动彼此重叠进行，可以提升性能
* 构造服务器的三种方法：
  * 多线程：并行性、阻塞系统调用
  * 单线程进程：无并行性、阻塞系统调用
  * 有限状态机：并行性、非阻塞系统调用、中断



### 经典的线程模型

* 各个线程都可以访问进程地址空间中的每一个内存地址。（线程之间是没有保护的）
* 每个进程中的内容
  * 地址空间
  * 全局变量
  * 打开文件
  * 子进程
  * 即将发生的定时器
  * 信号与信号处理程序
  * 账户能力
* 每个线程中的内容
  * 程序计数器
  * 寄存器
  * 堆栈
  * 状态
* 资源管理的单位是进程而非线程



> Q: UNIX中的fork系统调用。如果父进程有多个线程，那么它的子进程也应该拥有这些线程吗？
>
> A: 如果不是，则该子进程可能会工作不正常；如果是，父进程在read系统调用上被阻塞了会发生什么情况？



#### 常见的线程调用

* `thread_create`
  * 进程通常会从当前的单个线程开始。这个线程可以通过调用`thread_create`创建新的线程
* `thread_exit`
  * 当一个线程完成工作，可以通过调用`thread_exit`退出
* `thread_join`
  * 一个线程可以等待一个特定的线程退出。
* `thread_yielf`
  * 它允许线程自动放弃CPU从而让另一个线程运行。



### POSIX线程

| 线程调用             | 描述                           |
| -------------------- | ------------------------------ |
| pthread_create       | 创建一个新线程                 |
| pthread_exit         | 结束调用的线程                 |
| pthread_join         | 等待一个特定的线程退出         |
| pthread_yield        | 释放CPU来运行另外一个线程      |
| pthread_attr_init    | 创建并初始化一个线程的属性结构 |
| pthread_attr_destroy | 删除一个线程的属性结构         |



### 在用户空间中实现线程

把整个线程包放在用户空间中，内核对线程包一无所知。

{% asset_img 用户级线程包和内核管理的线程包.png 用户级线程包和内核管理的线程包 %}

* 在用户空间管理线程时，每个进程需要有其专用的**线程表**
* 使用用户级线程包的优点：
  * 进行一个线程切换比陷入内核要快
  * 允许每个进程有自己定制的调度算法
* 使用用户级线程包的缺点：
  * 难以实现阻塞系统调用（要允许每个线程使用阻塞调用，还要避免被阻塞的线程影响其他的线程）
  * 如果一个线程开始运行，那么在该进程中的其他线程就不能运行，除非第一个线程自动放弃CPU
    * 在一个单独的进程内部，没有时钟中断，所以不可能用轮转调度的方式调度线程
  * 我们通常在经常发生线程阻塞的应用中才希望使用多个线程。对于那些基本上是CPU密集型而且极少有阻塞的应用程序而言，没有使用多线程的意义。



### 在内核中实现线程

* 当某个线程希望创建一个新线程或撤销一个已有线程时，它进行了一个系统调用，这个系统调用通过对线程表的更新完成线程创建或撤销工作。
* 当一个线程阻塞时，内核根据其选择，可以运行同一个进程中的另一个线程或者运行另一个进程中的线程。而在用户级线程中，运行时系统始终运行自己进程中的线程，直到内核剥夺它的CPU为止。
* 信号是发给进程而不是线程的。



### 混合实现

使用内核级线程，然后将用户级线程与某些或者全部内核线程多路复用起来。

{% asset_img 用户级线程与内核线程多路复用.png 用户级线程与内核线程多路复用 %}

* 内核只识别内核级线程，并对其进行调度
* 其中一些内核级线程会被多个用户级线程多路复用



### 调度程序激活机制

> 调度程序激活工作的目标是模拟内核线程的功能，但是为线程包提供通常在用户空间中才能实现的更好的性能和更大的灵活性。

* 如果用户线程从事某种系统调用时是安全的，那就不应该进行专门的非阻塞调用或者进行提前检查



### 使单进程代码多线程化

把单进程的代码多线程化会碰到以下问题：

* 针对全局变量（对线程而言是全局变量，并不是对整个程序是全局的）
  * 禁用全局变量
  * 为每个线程赋予其私有的全局变量
  * 可以引入新的库过程，以便创建、设置和读取这些线程范围的全局变量
* 有许多库并不是可重入的
  * 为每个过程提供一个包装器，该包装器设置一个二进制位从而标志某个库处于使用中
* 对于信号的捕捉应该用什么线程



## 进程间通信

* 一个进程如何把信息传递给另一个
* 确保两个或更多的进程在关键活动中不会出现交叉
* 与正确的顺序有关



### 竞争条件

> 两个或多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序，称为**竞争条件**。



### 临界区

* 可以通过**互斥**的手段来避免**竞争条件（condition race）**。
* 把对共享内存进行访问的片段称作**临界区域（critical region）**。使两个进程不可能同时处于临界区中，就能够避免竞争条件。



### 忙等待的互斥

有以下几种实现互斥的方案：



#### 屏蔽中断

使每个进程在刚刚进入临界区后立即屏蔽所有中断，并在就要离开之前在打开中断。CPU只有发生时钟中断或其他中断时才会进行进程切换，这样，在屏蔽中断之后CPU将不会被切换到其他进程。



缺点：

屏蔽中断对于操作系统本身而言是一项很有用的技术，但对于用户进程则不是一种合适的通用互斥机制。



#### 锁变量

进入临界区之前，先读取锁变量的值。



缺点：

可能会导致领个进程进入临界区



### 严格轮换法

```java
// Thread A
while (true) {
  while (turn != 0) {
    critical_region();
  }
  turn = 1;
  noncritical_region();
}


// Thread B
while (true) {
  while (turn != 1) {
    critical_region();
  }
  turn = 0;
  noncritical_region();
}
```



* 连续测试一个变量直到某个值出现为止，称为**忙等待（busy waiting）**。
* 但这种方式非常消耗CPU资源，只有在有理由认为等待时间是非常短的情况下，才使用忙等待。用于忙等待的锁，称为**自旋锁（spin lock）**。



缺点：

* 只能轮流，在一个进程比另一个进程慢很多的情况下，轮流进入临界区并不是一个好办法。





### Peterson解法



### TSL指令

一种硬件支持的方案：

`TSL RX, LOCK` 称为**测试并加锁（test and set lock）**

* 它将一个内存字lock读到寄存器RX中，然后在该内存地址上存一个非零值。
* 这是一个原子操作。



锁住存储总线不同于屏蔽中断

* 屏蔽中断，然后在读内存字之后跟着写操作并不能阻止总线上的第二个处理器在读操作和写操作之间访问该内存字。



```shell
enter_region:
	# 复制锁到寄存器并将锁设为1
	TSL REGISTER, LOCK
	# 锁是零嘛？
	CMP REGISTER, #0
	# 若不是零，说明锁已被设置，所以循环
	JNE enter_region
	# 返回调用者，进入临界区
	
leave_region:
	# 在锁中存入0
	MOVE LOCK, #0
	# 返回调用者
	RET
```





### 睡眠与唤醒

> 优先级反转问题：
>
> 一台计算机有两个进程，H优先级较高，L优先级较低。调度规定，只要H处于就绪态它就可以运行。在某一时刻，L处于临界区中，此时H变到就绪态，准备运行。现在H开始忙等待，但由于当H就绪时L不会被调度，也就无法离开临界区，所以H将永远忙等待下去。



`sleep`是一个将引起调用进程阻塞的系统调用，即被挂起，直到另一个进程将其唤醒。

`wakeup`调用有一个参数，即要被唤醒的进程。





#### 生产者-消费者问题







### 信号量



用信号量解决生产者-消费者问题





### 互斥量





### 管程（Monitor）

一个管程是一个由过程、变量及数据结构等组成的集合，它们组成一个特殊的模块或软件包。

目的：使用信号量时要非常小心，管程更易于编写正确的程序



```java

```





### 消息的传递





### 屏障

可以通过在每个阶段的结尾安置**屏障**来实现这种行为。当一个进程到达屏障时，它就会被屏障阻拦，知道所有进程都到达该屏障为止。





## 调度

> 在操作系统中，完成选择工作的这一部分称为**调度程序**，该程序使用的算法称为**调度算法**



### 调度简介



#### 进程行为

* 几乎所有进程的（磁盘或网络）I/O请求和计算都是交替突发的。
* 计算密集型 vs. I/O密集型
  * 计算密集型：进程花费了绝大多数时间在计算上
  * I/O密集型：进程在等待I/O上花费了绝大多数时间



#### 何时调度

1. 在创建一个新的进程之后，需要决定是运行父进程还是运行子进程
2. 在一个进程退出时必须做出调度决策
3. 当一个进程阻塞在I/O和信号量上或由于其他原因阻塞时，必须选择另一个进程运行
4. 在一个I/O中断发生时，必须做出调度决策







#### 调度算法分类

抢占式 vs. 非抢占式

* **非抢占式**调度算法挑选一个进程，然后让该进程运行直至被阻塞，或者直到该进程自动释放CPU。
  * 在时钟中断发生时不会进行调度。
  * 在处理完时钟中断后，如果没有更高优先级级的进程等待到时，则中断的进程会继续执行。

* **抢占式**调度算法挑选一个进程，并且让该进程运行某个固定时段的最大值。
  * 如果在该时段结束时，该进程仍在运行，它就被挂起，而调度程序挑选另一个进程运行。
  * 进行抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把CPU控制返回给调度程序



三种环境：

* 批处理
  * 不会有用户不耐烦地在终端等待一个短请求的快捷响应。
  * 可以选择非抢占式算法，或对每个进程都有长时间周期的抢占式算法
* 交互式
  * 避免一个进程霸占CPU拒绝为其他进城服务，抢占是必需的
* 实时
  * 实时系统指系统的计算正确性不仅取决于计算的逻辑正确性，还取决于产生结果的时间。如果未满足系统的时间约束，则认为系统失效。
  * 实时系统只运行那些用来推进现有应用的程序，而交互式系统是通用的



#### 调度算法的目标

* 公平：相似的进程应得到相似的服务
* 保持系统的所有部分尽可能忙碌



可以通过几个指标来掌握系统的工作状态：



* 批处理系统：
  * **吞吐量**：系统每小时完成的作业数量
  * **周转时间**：从一个批处理作业提交时刻开始直到该作业完成时刻为止的统计平均时间
  * **CPU利用率**：用于对批处理系统的度量

* 交互式系统：
  * 响应时间：发出命令到得到响应之间的时间。

* 实时系统：
  * 可预测性



### 批处理系统的调度

#### 先来先服务（first-come first-served）

进程按照它们请求CPU的顺序使用CPU



#### 最短作业优先

当输入队列中有若干个同等重要的作业被启动时，调度程序应使用**最短作业优先**算法



#### 最短剩余时间优先

调度程序总是选择剩余运行时间最短的那个进程运行



### 交互式系统中的调度

#### 轮转调度

* 每个进程被分配一个时间段，称为**时间片（quantum）**，即允许该进程在该时间段中运行。
* 实现时间片轮转调度需要调度程序维护一张可运行进程列表。
* 从一个进程切换到另一个进程是需要一定时间进行管理事务处理——**上下文切换**（进程切换）
  * 保存和装入寄存器值及内存映像
  * 更新各种表格和列表
  * 清除和重新调入内存告诉缓存
* 时间片设的太短会导致过多的进程切换，降低了CPU效率；而设的太长又可能引起对短的交互请求的响应时间变长。



#### 优先级调度

* 每个进程被赋予一个优先级，允许优先级最高的可运行进程先运行

* 优先级可以静态赋予或动态赋予
  * 使I/O密集型进程获得较好服务：将其优先级设为*1/f*，*f* 为该进程在上一时间片中所占的部分。即占用的时间越多，优先级越高



#### 多级队列

* 为CPU密集型进程设置较长的时间片比频繁地分给它们很短的时间片要更为高效
* 不同优先级设立不同的时间片（最高优先级运行一个时间片，次高优先级运行两个时间片......）



#### 最短进程优先

通过首先运行最短的作业来使响应时间最短。



#### 保证调度



#### 彩票调度



#### 公平分享调度





### 实时系统中的调度

实时系统是一种**时间**起着主导作用的系统。



硬实时 vs. 软实时

* 硬实时：必须满足绝对的截止时间
* 软实时：可以容忍偶尔错失截止时间



实时系统也可以按照响应方式分为

* 周期性：以规则的时间间隔发生
* 非周期性：发生时间不可预知



### 线程调度

* 当若干进程都有多个线程，就存在两个层次的并行：进程和线程

* 在支持线程的操作系统上，内核级线程才是操作系统所调度的。用户级线程是由线程库来进行管理的，而内核并不知道他们。



#### 用户级线程

选取一个进程A，并给予进程时间片控制。A中的线程调度程序决定哪个线程运行，假设为A1。由于多道线程并不存在时钟中断，所以这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全部时间片，内核就会选择另一个进程运行。



#### 内核级线程

内核选择一个特定的线程运行，不需要考虑该线程属于哪个进程，对被选择的线程赋予一个时间片，如果超过了时间片，就会强制挂起线程。



用户级线程和内核级线程之间的差别在于性能。用户级线程的线程切换需要少量的机器指令，而内核级线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这导致了若干数量级的延迟。







# 内存管理

操作系统中管理分层存储器体系的部分称为**存储管理器**。它的任务是有效地管理内存，即记录哪些内存是正在使用的，哪些内存是空闲的；在进程需要时为其分配内存，在进程使用完后释放内存。



## 一种存储器抽象：地址空间

避免对进程暴露物理地址



### 地址空间的概念

> **地址空间**是一个进程可用于寻址内存的一套地址集合。每个进程都有一个自己的地址空间，并且这个地址空间独立于其他进程的地址空间



#### 基址寄存器与界限寄存器

* 使用**动态重定位**，简单地把每个进程的地址空间映射到物理内存的不同部分。
* 当使用基址寄存器和界限寄存器时，程序装载到内存中连续的空闲位置且装载期间无需重定位。





### 交换技术

有两种处理内存超载的通用方法：

* **交换**技术：即把一个进程完整调入内存，使该进程运行一段时间，然后把它存回磁盘。
* **虚拟内存**：能使程序在只有一部分被调入内存的情况下运行。



{% asset_img 交换.png 交换 %}

存在的问题：

如果进程的数据段可以增长（允许从堆中动态地分配内存），那么当进程空间试图增长时，就会出现问题。如果我们提前预留一些额外的空间，也会造成浪费。





### 空闲内存管理

在动态分配内存时，操作系统必须对其进行管理。有以下两种方式跟踪内存使用情况：**位图**和**空闲区域表**



#### 位图

{% asset_img 位图.png 位图 %}

在决定把一个占*k*个分配单元的进程调入内存时，存储管理器必须搜索位图，在位图中找出有*k*个连续0的串。



#### 空闲区域表

维护一个记录已分配内存段和空闲内存段的链表。



当按照地址顺序在链表中存放进程和空闲区时，有以下几种方法可以用来为创建的进程分配内存：

* 首次适配算法
* 下次适配算法
* 最佳适配算法
* 最差适配算法
* 快速适配算法
  * 为那些常用大小的空闲区维护单独的链表。



## 虚拟内存

每个程序拥有自己的地址空间，这个空间被分割成多个块，每个块称为一**页（page）**。每一页有连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻执行必要的映射。当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令。



### 分页

* 由程序产生的这些地址称为**虚拟地址**，它们构成了一个**虚拟地址空间**。
* 在使用虚拟内存的情况下，虚拟地址不是被直接送到内存总线上，而是被送到**内存管理单元（Memory Management Unit, MMU）**，MMU把虚拟地址映射为物理内存地址。
* 虚拟地址空间按照固定大小划分成被称为页面的若干单元。在物理内存中对应的单元称为**页框**。页面和页框的大小通常是一样的。



当程序访问一个未映射的页面：

MMU注意到该页面没有被映射，于是CPU陷入到操作系统，这个陷进称为**缺页中断**或**缺页错误**。





### 页表

虚拟地址被分为虚拟页号（高位部分）和偏移量（低位部分）两部分。

{% asset_img 页表项.png 页表项 %}

* 最重要的是**页框号**，页映射的目的就是找这个值。



### 加速分页过程

我们主要考虑两个问题：

1. 虚拟地址到物理地址的映射必须非常快
2. 如果虚拟地址空间很大，页表也会很大



#### 转换检测缓冲区

> 计算机设置一个小型的硬件设备，将虚拟地址直接映射到物理地址，而不必在访问页表。这种设备称为**转换检测缓冲区（TLB）**,有时又称为**相联存储器**或**快表**。



* 每个表项记录了一个页面的相关信息，包括虚拟页号、页面的修改位保护码和该页所对应的物理页框。

* 当虚拟号不在TLB中，就会进行正常的也页表查询，接着从TLB中淘汰一个表项，然后用新找到的页表项代替它。
  * 当一个表项被清除出TLB时，将修改位复制到内存中的页表项，而除了访问位，其他的值不变。
  * 当页表项中从页表中装入TLB中时，所有的值都来自内存。



### 针对大内存的页表

引入TLB可以加快虚拟地址到物理地址的转换。那么要怎样处理巨大的虚拟地址空间：



#### 多级页表





#### 倒排页表

> 实际内存中的每个页框对应一个表项，而不是每个虚拟页面对应一个表项。表项记录了哪一个（进程，虚拟页面）对定位于该页框。





## 页面置换算法

当发生缺页中断时，操作系统必须在内存中选择一个页面将其换出内存，以便为即将调入的页面腾出空间。如果要换出的页面在内存驻留期间已经被修改过，就必须把它写回磁盘已更新该页面在磁盘的副本；如果该页面没有被修改过，那么它在磁盘上的副本已经是最新的，不需要回写。



### 最优页面置换算法

> 在缺页中断发生时，有些页面在内存中，其中有一个页面将很快被访问，其他页面则可能要到10、100或1000条指令后才会被访问，每个页面都可以用在该页面首次被访问前要执行的指令数作为标记。

但这是一个理想化模型，当缺页中断发生时，操作系统无法知道各个页面下一次将在什么时候被访问。



### 最近未使用页面置换算法

**NRU**算法随机地从类编号最小的非空类中挑选一个页面淘汰。

* 第一类：没有被访问，没有被修改
* 第二类：没有被访问，已被修改
* 第三类：已被访问，没有被修改
* 第四类：已被访问，已被修改



### 先进先出页面置换算法

操作系统维护一个所有当前在内存中的页面的链表，最新进入的页面放在表尾，最早进入的页面放在表头。当发生缺页中断时，淘汰表头的页面并把新调入的页面加到表尾。



### 第二次机会页面置换算法

FIFO算法可能会把经常使用的页面置换出去。我们为此进行一个简单的改进：检查最老页面的R位。如果R位是0，那么这个页面既老又没有被使用，可以立即置换掉；如果是1，就将R位清零，并把该页面放到链表的尾端。



### 最近最少使用页面置换算法（LRU）

在缺页中断发生时，置换未使用时间最长的页面。

需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。困难的是在每次访问内存时都必须要更新整个链表。



## 分页系统中的设计问题

### 局部分配策略与全局分配策略



{% asset_img 局部页面置换与全局页面置换.png 局部页面置换与全局页面置换 %}

局部算法可以有效地为每个进程分配固定的内存片段；全局算法在可运行进程之间动态地分配页框。



### 负载控制











