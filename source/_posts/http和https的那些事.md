---
title: http和https的那些事
date: 2020-07-14 09:56:28
tags:
---
# HTTP
## HTTP 基本概念

<b>HTTP（超文本传输协议，HyperText Transfer Protocol)</b>是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。是用于从WWW服务器传输超文本到本地浏览器的传输协议。默认使用80端口，HTTP客户端发起一个请求，建立一个到服务器指定端口（默认是80端口）的TCP连接，但是具体的通信不是在80端口。

我们可以把它拆成三个部分去理解
* 超文本
* 传输
* 协议

> 协议

HTTP 是一个用在计算机世界里的**协议**。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（两个以上的参与者），以及相关的各种控制和错误处理方式（行为约定和规范）。

> 传输 

HTTP 协议是一个**双向协议**

HTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。

> 超文本

我们先来理解「文本」，在互联网早期的时候只是简单的字符文字，但现在「文本」的涵义已经可以扩展为图片、视频、压缩包等，在 HTTP 眼里这些都算作「文本」。

再来理解「超文本」，它就是超越了普通文本的文本，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。

HTML 就是最常见的超文本了，它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，再经过浏览器的解释，呈现给我们的就是一个文字、有画面的网页了。

那么经过上面一系列分析，就可以给出比「超文本传输协议」这七个字更准确更有技术含量的答案：

> HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。

HTTP协议和TCP协议是不冲突的，HTTP定义在七层协议中的应用层，TCP解决的是传输层的逻辑。HTTP使用TCP而不是UDP的原因在于（打开）一个网页必须传送很多数据，而TCP协议提供传输控制，按顺序组织数据，和错误纠正。所以<b>HTTP是一个基于TCP/IP通信协议来传递数据</b>。也要经过三次握手和四次挥手。

<b>HTTP协议的瓶颈及其优化技巧都是基于TCP协议本身的特性。</b>如TCP建立连接时三次握手有1.5个RTT（round-trip time）的延迟，为了避免每次请求的都经历握手带来的延迟，应用层会选择不同策略的http长链接方案。(长连接和短连接会在下文中补充)又如TCP在建立连接的初期有慢启动（slow start）的特性，所以连接的重用总是比新建连接性能要好。

HTTP连接使用的是“请求—响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务器端才能回复数据。HTTP/1.0是第一个在通讯中指定版本号的HTTP 协议版本，至今仍被广泛采用，特别是在代理服务器中。

HTTP/1.1是当前版本，持久连接被默认采用，并能很好地配合代理服务器工作，还支持以管道方式同时发送多个请求，以便降低线路负载，提高传输速度。HTTP／2.0在HTTP 1.x的基础上，大幅度的提高了web性能，减少了网络延迟。HTTP1.0和1.1在之后很长的一段时间内会一直并存，这是由于网络基础设施更新缓慢所决定的。

### 常见的状态码

## GET与POST




## HTTP 是无状态的

https://www.zhihu.com/question/23202402


## HTTP 1.0
HTTP 协议老的标准是HTTP/1.0，为了提高系统的效率，HTTP 1.0规定浏览器与服务器只保持<b>短暂的连接</b>，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。

但是，这也造成了一些性能上的缺陷，例如，一个包含有许多图像的网页文件中并没有包含真正的图像数据内容，而只是指明了这些图像的URL地址，当WEB浏览器访问这个网页文件时，浏览器首先要发出针对该网页文件的请求，当浏览器解析WEB服务器返回的该网页文档中的HTML内容时，发现其中的图像标签后，浏览器将根据标签中的src属性所指定的URL地址再次向服务器发出下载图像数据的请求。显然，访问一个包含有许多图像的网页文件的整个过程包含了多次请求和响应，每次请求和响应都需要建立一个单独的连接，每次连接只是传输一个文档和图像，上一次和下一次请求完全分离。即使图像文件都很小，但是客户端和服务器端每次建立和关闭连接却是一个相对比较费时的过程，并且会严重影响客户机和服务器的性能。当一个网页文件中包含JavaScript文件，CSS文件等内容时，也会出现类似上述的情况。

同时，带宽和延迟也是影响一个网络请求的重要因素。在网络基础建设已经使得带宽得到极大的提升的当下，大部分时候都是延迟在于响应速度。基于此会发现，http1.0被抱怨最多的就是<b>连接无法复用</b>，和<b>head of line blocking</b>这两个问题。理解这两个问题有一个十分重要的前提：客户端是依据域名来向服务器建立连接，一般PC端浏览器会针对单个域名的server同时建立6～8个连接，手机端的连接数则一般控制在4～6个。显然连接数并不是越多越好，资源开销和整体延迟都会随之增大。连接无法复用会导致每次请求都经历三次握手和慢启动。（多个连接的请求每次都要重新来）三次握手在高延迟的场景下影响较明显，慢启动则对文件类大请求影响较大。head of line blocking会导致带宽无法被充分利用，以及后续健康请求被阻塞。

head of line blocking(holb)会导致健康的请求会被不健康的请求影响，而且这种体验的损耗受网络环境影响，出现随机且难以监控。为了解决holb带来的延迟，协议设计者设计了一种新的pipelining机制。pipelining只能适用于http1.1,而且由于使用苛刻，很多浏览器厂商并不支持。

tips: head of line blocking是队头阻塞，是指一列的第一个数据包（队头）受阻而导致整列数据报受阻。
## HTTP 1.1

相较于HTTP1.0，HTTP1.1主要做了如下改动：
### 长连接
* 为了克服HTTP 1.0的这个缺陷，HTTP 1.1支持持久连接（HTTP/1.1的默认模式使用**带流水线的持久连接**），在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。
    * HTTP/1.1协议的持续连接有两种方式，即**非流水线方式和流水线**方式。非流水线方式的特点是，客户在收到前一个响应后才能发出下一个请求；流水线方式的特点是，客户在收到HTTP的响应报文之前就能接着发送新的请求报文。
* 一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。
* 在 HTTP1.1 中默认开启 Connection： keep-alive，一定程度上弥补了 HTTP1.0 每次请求都要创建连接的缺点。

### 缓存处理
* 在 HTTP1.0 中主要使用 header 里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。
### 带宽优化及网络连接的使用
* HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了range 头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
    
### 错误通知的管理
* 在 HTTP1.1 中新增了24 个错误状态响应码，如 409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

### Host头处理
* 在 HTTP1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个 IP 地址。HTTP1.1 的请求消息和响应消息都应支持 Host 头域，且请求消息中如果没有 Host 头域会报告一个错误（400 Bad Request）。
* HTTP/1.0不支持文件断点续传，<code>RANGE:bytes</code>是HTTP/1.1新增内容，HTTP/1.0每次传送文件都是从文件头开始，即0字节处开始。<code>RANGE:bytes=XXXX</code>表示要求服务器从文件XXXX字节处开始传送，这就是我们平时所说的断点续传！
* HTTP 1.1的持续连接，也需要增加新的请求头来帮助实现，例如，Connection请求头的值为Keep-Alive时，客户端通知服务器返回本次请求结果后保持连接；Connection请求头的值为close时，客户端通知服务器返回本次请求结果后关闭连接。HTTP 1.1还提供了与身份认证、状态管理和Cache缓存等机制相关的请求头和响应头。

在http1.1，request和reponse头中都有可能出现一个connection的头，此header的含义是当client和server通信时对于长链接如何进行处理。
在http1.1中，client和server都是默认对方支持长链接的， 如果client使用http1.1协议，但又不希望使用长链接，则需要在header中指明connection的值为close；如果server方也不想支持长链接，则在response中也需要明确说明connection的值为close。不论request还是response的header中包含了值为close的connection，都表明当前正在使用的tcp链接在当天请求处理完毕后会被断掉。以后client再进行新的请求时就必须创建新的tcp链接了。

缺点：
* 虽然HTTP1.1允许复用TCP连接，但是仍然没有解决队头阻塞的问题
* HTTP1.x使用的都是**明文**传输，无法保证传输的安全性(后面会介绍使用HTTPS来增加传输的安全性)
* HTTP1.x使用时，header里携带的内容过大，在一定程度上增加了传输的成本，并且每次请求 header 基本不怎么变化，尤其在移动端增加用户流量。
* `keep-alive`会给服务端带来巨大的性能压力，因为它在文件被请求后还保持了不必要的连接


## SPDY 协议
SPDY 协议综合了HTTPS和HTTP两者于一体的传输协议

### 降低延迟
* 采用**多路复用(multiplexing)**。多路复用通过多个请求stream共享一个TCP连接的方式，解决了holb(head of line blocking)的问题，降低了延时同时提高了带宽的利用率。
### 请求优先级
* 多路复用带来一个新的问题是，在连接共享的基础之上有可能会导致关键请求被阻塞。SPDY 允许给每个 request 设置优先级，这样重要的请求就会优先得到响应。比如浏览器加载首页，首页的 html 内容应该优先展示，之后才是各种静态资源文件，脚本文件等加载，这样可以保证用户能第一时间看到网页内容。
### header压缩
* 前面提到 HTTP1.x 的 header 很多时候都是重复多余的。选择合适的压缩算法可以减小包的大小和数量。
### 基于HTTPS的加密传输，大大提高了传输数据的可靠性
### 服务端推送(server push) 
* 采用了SPDY的网页
### SPDY构成图:

    {% asset_img SPDY.png SPDY %}

## HTTP 2.0
HTTP 2.0是SPDY的升级版，主要有以下两点区别：
* HTTP2.0 支持明文 HTTP 传输，而 SPDY 强制使用 HTTPS
* HTTP2.0 消息头的压缩算法采用 HPACK，而非 SPDY 采用的 DEFLATE

### 二进制分帧
#### 基本概念
* 连接(Connection)
    * 一个TCP连接包含多个stream
* 流(Stream)
    * 流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标识符（1、2…N）
    * 在建立连接后，一次的请求与被响应，可以看作流
    * 一个双向通讯数据流，包含一条或多条message
* 消息(Message)
    * 是指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧(frame)组成。
* 帧(Frame)
    * 客户端与服务器通过交换帧来通信，帧是基于这个新协议通信的最小单位，以二进制压缩格式存放 HTTP1.x 中的内容。
    * 每一帧都包含几个字段,`length`, `type`, `flags`等。


HTTP/2 采用二进制格式传输数据，而非 HTTP 1.x 的文本格式，二进制协议解析起来更高效。 HTTP / 1 的请求和响应报文，都是由起始行，首部和实体正文（可选）组成，各部分之间以文本换行符分隔。HTTP 2.0将请求和响应数据分割为更小的帧，并且它们采用二进制编码。

* 帧、流、消息的关系

    {% asset_img 流-消息-帧.png 流-消息-帧 %}

### 多路复用
多路复用代替原来的序列和阻塞机制，所有的请求都是通过一个TCP连接并发的完成。同时也很好的解决了浏览器限制同一个域名下的请求数量的问题。
* 同域名下所有的通信都是在单个连接上完成，同个域名只需要占用一个TCP连接，使用一个连接并行发送多个请求和响应。
* 单个连接可以承载任意数量的双向数据流，单个连接上可以并行交错的请求和响应，之间互不干扰。
* 数据流以消息的形式发送，而消息又有一个或多个帧组成，多个帧之间可以乱序发送，因为根据帧首部的流标识可以重新组装。每个请求都可以带一个31bits的优先值，0表示最高优先级，数值越大优先级越低。

https://juejin.im/post/5d70848df265da03d871de9c


HTTP 2.0 的多路复用其实是 HTTP 1.1 中长连接的升级版本。

在 HTTP 1.1 中，一次链接成功后，只要该链接还没断开，那么 client 端可以在这么一个链接中有序地发起多个请求，并以此获得每个请求对应的响应数据。它的缺点是，一次请求与响应的交互必须要等待前面的请求交互完成，否则后面的只能等待，这个就是<b>线头阻塞.</b> 下面举个例子：

> 请求A 和 请求B。A 先被发起，此时 server 端接收到了 A 请求，正在处理。同时 B 请求也发过来了。但是 A 请求还没被返回，此时 B 请求只能等待。

在 HTTP 2.0 中，一次链接成功后，只要链接还没断开，那么 client 端就可以在一个链接中并发地发起多个请求，每个请求及该请求的响应不需要等待其他的请求，某个请求任务耗时严重，不会影响到其它连接的正常执行。

 {% asset_img 多路复用.png 多路复用 %}


### 首部压缩
HTTP1.x 的 header 带有大量信息，而且每次都要重复发送，HTTP2.0 使用 encoder 来减少需要传输的header大小，通讯双方各自cache一份header fields表，既<b>避免了重复 header 的传输</b>，<b>又减小了需要传输的大小</b>。

* HTTP 2.0 在客户端和服务端使用"首部表"来跟踪和存储之前发送的键 - 值对，不再重复发送header
* 首部表在HTTP 2.0 的连接存续期内始终存在，由客户端和服务器共同渐进地更新
* 每个新的首部键－值对要么被追加到当前表的末尾，要么替换表中之前的值

>示例：

 {% asset_img 首部压缩.png 首部压缩 %}

### 服务端推送
Server Push 即服务端能通过 push 的方式将客户端需要的内容预先推送过去，也叫 "cache push". 服务器可以对一个客户端请求发送多个响应。服务器向客户端推送资源无需客户端明确地请求，服务端可以提前给客户端推送必要的资源，这样可以减少请求延迟时间，例如服务端可以主动把 JS 和 CSS 文件推送给客户端，而不是等到 HTML 解析到资源时发送请求。

tips: 所有推送的资源都遵守同源策略。 服务器必须遵循请求- 响应的循环，只能借着对请求的响应推送资源。

## 参考文献
https://www.jianshu.com/p/52d86558ca57

https://juejin.im/post/5d7082bcf265da03f233ed9b


# HTTPS
## HTTPS 的加密方式
### 加密方式
* 对称加密
* 非对称加密
#### 对称加密

{% asset_img 对称加密.png 对称加密 %}

* 定义
    * 需要对加密和解密使用相同密钥的加密算法。所谓对称，就是采用这种加密方法的双方使用方式用同样的密钥进行加密和解密。密钥是控制加密及解密过程的指令。算法是一组规则，规定如何进行加密和解密。
* 算法实现
    * 可以参见https://juejin.im/post/5b48b0d7e51d4519962ea383 再次不作过多的叙述。

#### 非对称加密
由于使用对称加密的话，密钥是使用明文传输的，任然存在被截取的风险，这就是非对称加密的由来。

{% asset_img 非对称加密.png 非对称加密 %}

* 定义
    * 非对称加密算法需要两个密钥：公开密钥（publickey:简称公钥）和私有密钥（privatekey:简称私钥）。公钥与私钥是一对，如果用公钥对数据进行加密，只有用对应的私钥才能解密。如果用公钥对数据进行加密，只有用对应的私钥才能解密。因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法。

## 优化
由于非对称加密在加密的时候速度特别慢，比对称加密慢了上百倍。所以我们选用对称加密+非对称加密的形式。

### 对称加密+非对称加密：
服务器用明文的方式给客户端发送自己的公钥，客户端收到公钥之后，会生成一把密钥(对称加密用的)，然后用服务器的公钥对这把密钥进行加密，之后再把密钥传输给服务器，服务器收到之后进行解密，最后服务器就可以安全着得到这把密钥了，而客户端也有同样一把密钥，他们就可以进行对称加密了。

### 风险
服务器以明文的方式给客户端传输公钥的时候，中间人截取了这把属于服务器的公钥，并且把中间人自己的公钥冒充服务器的公钥传输给了客户端。之后客户端就会用中间人的公钥来加密自己生成的密钥。然后把被加密的密钥传输给服务器，这个时候中间人又把密钥给截取了，中间人用自己的私钥对这把被加密的密钥进行解密，解密后中间人就可以获得这把密钥了。最后中间人再对这把密钥用刚才服务器的公钥进行加密，再发给服务器。

非对称加密之所以不安全，是因为客户端不知道这把公钥是不是属于服务器的。如何解决这个问题呢，就需要引入**数字证书**。

## 数字证书
* 我们需要找到一个拥有公信力、大家都认可的认证中心(CA)。
* 服务器在给客户端传输公钥的过程中，会把公钥以及服务器的个人信息通过Hash算法生成**信息摘要**。
* 为了防止信息摘要被人调换，客户端还会用CA提供的私钥对信息摘要进行加密来形成**数字签名**。
* 把原来没Hash算法之前的个人信息以及公钥 和 数字签名合并在一起，形成**数字证书**。

{% asset_img 数字证书_服务端.png 数字证书_服务端 %}

* 当数字证书拿到这份数字证书的时候，就会用CA提供的公钥来对数字证书里面的数字签名进行解密来得到信息摘要，然后对数字证书里服务器的公钥以及个人信息进行Hash得到另外一份信息摘要。最后把两份信息摘要进行对比，如果一样，则证明这个人是服务器。

{% asset_img 数字证书_客户端.png 数字证书_客户端 %}

> 客户端如何获得CA的公钥, 服务器又怎么会有CA的私钥

其实，(有些)服务器一开始就向认证中心申请了这些证书了(有没有看过没有证书的网站在地址栏会被标出警告？)，而客户端是，也会内置这些证书。当客户端收到服务器传输过来的数据数字证书时，就会在内置的证书列表里，查看是否有解开该数字证书的公钥。


### 参考文献
https://segmentfault.com/a/1190000019687184

https://labuladong.gitbook.io/algo/labuladong-he-ta-de-peng-you-men/30-zhang-tu-jie-http-chang-jian-mian-shi-ti
