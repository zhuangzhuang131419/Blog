---
title: 《数据密集型应用系统设计》-读书笔记2
date: 2021-01-27 13:02:07
category: 分布式系统
tags: [读书笔记,数据密集型应用系统设计]
---

# 第二部分：分布式数据系统

* 扩展性
  * 当数据量或者读写负载巨大，严重超出了单台机器的处理上限，需要将负载分散到多台机器上。
* 容错和高可用性
  * 当单台机器出现故障，还希望应用系统可以继续工作，这是需要采用多台机器提供冗余。
* 延迟考虑
  * 如果客户遍布世界各地，通常需要考虑在全球范围内部署服务，以方便用户就近访问最近数据中心所提供的服务。

## 系统扩展能力

当负载增加需要更强的处理能力时，最简单的办法就是购买更强大的机器（垂直扩容）。

* **共享内存架构**
  * 所有这些组件的集合可看做一台大机器。
  * 共享内存架构的问题在于，成本增长过快甚至超过了线性：两倍的CPU，两倍的内存，两倍的磁盘容量可能不能将成本控制在两倍。
* **共享磁盘架构**
  * 拥有多台服务器，每个服务器各自拥有独立的CPU和内存，然后将数据存储在可共享访问的磁盘阵列上。
  * 服务器与磁盘阵列之间往往通过高速网络连接。

## 无共享结构

与上面的垂直扩容相比较之下，无共享架构优点更加明显。

* 运行数据库软件的机器或者虚拟机成为**节点**。
* 每个**节点**独立使用本地的CPU，内存和磁盘。
* 节点之间的多有协调通信等任务全部运行在传统网络之上且核心逻辑主要依靠软件来实现。



## 复制与分区

* 复制
  * 在多个节点上保存相同数据的副本，每个副本具体的存储位置可能不尽相同。
* 分区
  * 将一个大块头的数据库拆分成多个较小的子集即**分区**，不同的分区分配给不同的节点。



# 第五章 数据复制







# 第六章 分区





# 第七章 事务

> 事务将应用程序的多个读、写操作捆绑在一起成为一个逻辑操作单元

但是并非每个应用程序都需要事务机制，有时可以弱化事务处理或完全放弃事务（为了实现更高的性能或更高的可用性）。



## 深入理解事务

随着非关系（NoSQL）数据库开始兴起。它们的目标是通过提供新的数据模型，以及内置的复制和分区等手段来改进传统的关系模型。



### ACID的含义

实际上，各家数据库所实现的ACID并不尽相同。



#### 原子性 Atomicity

有一个误区：

> ACID中的原子性并不关乎多个操作的并发性，它没有描述多个线程试图访问相同的数据会发生什么情况，这其实是隔离性所定义的。

ACID原子性实际上描述的是：

**客户端发起一个包含多个写操作的请求时可能发生的情况。**

在完成一部分写入操作后，系统发生了故障

* 进程崩溃
* 网络中断
* 磁盘变满
* 违反了某种完整性约束

出现了上述故障而导致无法完成最终提交时，事务会终止，数据库回滚。

> ACID中原子性所定义的特征是：在出错时中止事务，并将部分完成的写入全部丢弃。



#### 一致性 Consistency

一致性这个词目前有多种含义：

* 第五章讨论副本一致性以及异步复制模型时，引出最终一致性问题。
* 一致性哈希则是某些系统用于动态分区再平衡的方法。
* CAP理论中，一致性一词用来表示线性化。
* ACID中，一致性主要指数据库处于应用程序所期待的“预期状态”。



> 如果某事物从一个有效的状态开始，并且事务中任何更新操作都没有违背约束，那么最后的结果依然符合有效状态。

这种一致性本质要求应用层来维护状态一致，应用程序有责任正确的定义事务来保持一致性。

ACID中的一致性更多是应用层的属性。



#### 隔离性 Isolation

> 意味着并发执行的多个事务相互隔离，它们不能互相交叉。

* 串行性隔离
  * 虽然实际上它们可能同时运行，但数据库系统要确保当事务提交时，其结果与串行执行完全相同。
* 快照隔离
  * 提供了比串行化更弱的保证。



#### 持久性 Durability

> 保证一旦事务提交成功，即使存在硬件故障或数据库崩溃，事务所写入的任何数据也不会消失。



### 单对象与多对象事务操作

多对象事务目的通常是为了在多个数据对象之间保持同步。

对于关系数据库，客户端通常与数据库服务器建立TCP网络连接，因而对于特定的某个连接，SQL语句BEGIN TRANSACTION和COMMIT之间的所有操作都属于同一个事物。

例：电子邮件应用

* 其他用户看到要么是更新后的电子邮件和更新后的计数器，要么是两者都未更新，而不会是两者不一致。（隔离性）
* 如果事务执行过程中发生错误，导致邮箱和未读计数器二者不同步。则事务将被终止，且此前插入的电子邮件将被回滚。（原子性）



#### 单对象写入

* 存储引擎在单节点、单个对象层面上提供原子性和隔离性。
  * 出现宕机时，基于日志回复来实现原子性（第三章“可靠的B-Tree”）
  * 对每个对象采用加锁的方式来实现隔离，确保每次只允许一个线程访问对象。

* 某些数据库还提供了高级的原子操作
  * 原子自增操作
  * compare-and-set

> 通常意义上的事务针对的是多个对象，将多个操作聚合为一个逻辑执行单元。



#### 多对象事务的必要性

* 对于关系型数据模型，表中的某行可能是另一个表中的外键。
* 对于文档数据模型，更新非规范化数据时，就需要一次更新多个文档。此时多对象食物就可以有效防止非规范化数据之间出现不同步。
* 对于带有二级索引的数据库，每次更改值时都需要同步更新索引。



#### 处理错误与中止

> ACID数据库基于这样的一个理念：如果存在违反原子性、隔离性或持久性的风险，则完全放弃整个事务，而不是部分放弃。

* 如果事务实际已经执行成功，但返回给客户端的消息在网络传输时发生意外，那么重试就会导致重复执行，此时需要额外的应用级重复数据删除机制。
* 如果错误是由于系统超负荷所导致，则重试事务将使情况变得更槽。为此，可以设定一个重试次数上限，例如指数回退，同时要尝试解决系统过载本身的问题。
* 由临时性故障（例如死锁，隔离违例，网络闪断和节点切换等）所导致的错误需要重试。但出现永久性故障（例如违反约束），则重试毫无意义。
* 如果在数据库之外，事务还产生其他副作用，即使事务被终止，这些副作用可能已事实生效。可以采用两阶段提交。
* 如果客户端在重试过程中也发生失败，没有其他人继续负责重试，则那些待写入的数据可能会因此而丢失。



## 弱隔离级别

> 可串行化隔离（serializable）意味着数据库保证事务的最终执行结果与串行执行结果相同

但是往往可串行化隔离意味着性能方面的损失。需要我们在实际开发环境中进行选择。



### 读-提交 Read Committed

1. 读数据库时，只能看到已成功提交的数据。（防止脏读）

2. 写数据库时，只会覆盖已成功提交的数据。（防止脏写）

   

#### 防止脏读

> 脏读：某个事务已经完成部分数据写入，但事务尚未提交（或终止），另一个事务可以看到尚未提交的数据。

有以下需求时，需要防止脏读

* 事务需要更新多个对象，脏读意味着另一个事物可能会看到部分更新，而非全部。

* 如果事务发生终止，则所有写入操作都需要回滚。如果发生了脏读，这意味着他可能会看到一些稍后被回滚的数据。

  

#### 防止脏写

> 脏写：覆盖先写尚未提交事务的写入。

防止脏写可以避免：

* 如果事务需要更新多个对象，脏写会带来非预期的错误结果。

* 但是脏读不能解决“更新丢失”的问题。

  

#### 实现读-提交

数据库通常采用**行级锁**来防止脏写/读：

当事务想修改/读取某个对象（例如行或文档）时，它必须首先获得该对象的锁；然后一直持有锁直到事务提交（终止）。这种锁是由处于读-提交模式（或更强隔离级别）数据库自动完成的。

但是读锁在实际中并不可行，因为运行时间较长的写事务会导致许多只读的事务等待太久。

因此大多数数据库采用了多版本的方法来防止脏读：对于每个待更新的对象，数据库都会维护其旧值和当前持锁事务将要设置的新值两个版本。（在事务提交之前，所有其他读操作都读取旧值；仅当写事务提交之后，才会切换到读取新值）



### 快照级别隔离与可重复读 Snapshot Isolation and Repeatable Read

> 不可重复读：在一个事务中，两次读取的值不一样。

有些场景不允许这种不一致的情况发生：

* 备份场景
  * 在备份的过程中，可以继续写入数据库，得到的镜像里可能包含部分旧版本数据和部分新版本数据。如果从这样的备份进行恢复，最终就导致了永久性的不一致。
* 分析查询与完整性检查场景



可以使用**快照隔离级别**来解决上述问题。

> 每个事务都从数据库的一致性快照中读取，事务一开始所看到是最近提交的数据，即使数据随后可能被另一个事务更改，但保证每个事物都只看到该特定时间点的旧数据，



#### 实现快照级别隔离

快照级别隔离的实现通常采用写锁来防止脏写。但是，读取则不需要加锁。

> 数据库是采用多版本并发控制（MultiVersion Concurrency Control, MVCC）来实现快照级别隔离。

因为读-提交只需要保留对象的两个版本就足够了：一个已提交的旧版本和尚未提交的新版本。所以，支持快照级别隔离的存储引擎往往直接采用MVCC来实现读-提交隔离。

做法为：

* 在读-提交级别下，对每一个不同的查询单独创建一个快照
* 在快照级别下，使用一个快照来运行整个事务



#### 一致性快照的可见性规则

> 当事务读数据库时，通过事务ID可以决定哪些对象可见，哪些不可见。

当以下两个条件都成立，则该数据对象对事务可见：

* 事务开始时刻，创建该对象的事务已经完成了提交。
* 对象没有被标记删除；或者即使标记了，但删除事务在当前事务开始时还没有完成提交。



#### 索引与快照级别隔离

这种多版本数据库如何支持索引呢？

1. 索引直接指向对象的所有版本，然后想办法过滤对当前事务不可见的那些版本。
2. 采用追加/写时复制的技术。当需要更新时，不会修改现有的页面，而总是创建一个新的修改副本，拷贝必要的内容，然后让父结点，或者递归向上直到树的root结点都指向新创建的结点。
   * 每次写入事务都会创建一个新的B-Tree root，代表该时刻数据库的一致性快照。
   * 这时候就没有必要根据事务ID再去过滤掉某些对象，每笔写入都会修改现有的B-Tree，因为之后的查询可以直接作用于特定快照B-Tree。



### 防止更新丢失

当有两个事务在同样的数据对象上执行类似操作时，由于隔离性，第二个写操作并不包括第一个事务修改后的值，最终会导致第一个事务的修改值可能会丢失。

目前有以下集中解决方案：



#### 原子写操作

* 原子操作通常采用对读取对象加独占锁的方式来实现，这样在更新被提交之前不会被其他事务读取。
* 另一种实现方式是强制所有的原子操作都在单线程上执行。



#### 显示加锁

由应用程序显示锁定待更新的对象。

例如，考虑一个多人游戏，其中几个玩家可以同时移动同一个数字。只靠原子操作可能还不够，因为应用程序还需要确保玩家的移动还需要遵守其他游戏规则，这涉及一些应用层逻辑。



#### 自动监测更新丢失

原子操作和锁都是通过强制“读-修改-写回”操作序列串行执行来防止丢失更新。

也可以先让他们并发执行，但如果事务管理其检测到了更新丢失风险，则会终止当前事务，并强制回退到安全的“读-修改-写回”方式。

> MySQL/InnoDB的可重复读却并不支持检测更新丢失。



#### 原子比较和设置

在有的不提供事务支持的数据库中，会支持原子“比较和设置”操作。（只有在上次读取的数据没有发生变化时才允许更新；如果已经发生更新，则回退到“读-修改-写回”方式。）



#### 冲突解决与复制

由于多节点上的数据副本，不同的节点可能会并发修改数据，因此必须采取一些额外的措施来防止丢失更新。

对于多主节点或者无主节点的多副本数据库，由于支持多个并发写，且通常以异步方式来同步更新，所以会出现多个最新的数据副本。



多副本数据库通常支持多个并发写，然后保留多个冲突版本（互称为兄弟），之后由应用层逻辑或依靠特定的数据结构来解决、合并多版本。



将在第九章详细介绍。



### 写倾斜和幻读

可以把写倾斜视为一种更广义的更新丢失问题。

> 如果两个事务读取相同的一组对象，然后更新其中一部分：不同的事务可能更新不同的对象，则可能发生写倾斜；而不同的事务如果更新的是同一个对象，则可能发生脏写或更新丢失。



如果不能使用可串行化级别隔离，一个次优的选择是对事务依赖的行来显示的加锁。

```sql
BEGIN TRANSACTION;
SELECT * FROM doctors WHERE on_call = true AND shift_id = 1234 FOR UPDATE;
UPDATE doctors SET on_call = false WHERE name = 'Alice' AND shift_id = 1234;
COMMIT;
```



其中 `FOR UPDATE` 语句会通知数据库对返回的所有结果行自动加锁。



#### 为何会发生写倾斜

1. 首先输入一些匹配条件，即采用SELECT查询所有满足条件的行。
2. 根据查询的结果，应用层代码来决定下一步的操作。
3. 如果应用程序决定继续执行，它将发起数据库写入（INSERT, UPDATE 或 DELETE）并提交事务。**而这个写操作通常会改变步骤2做出的前提条件。**



#### 实体化冲突

并没有看懂书中的意思



## 串行化

可串行化隔离是最强的隔离级别。它保证即使事务可能会并行执行，但最终的结果与每次一个个串行执行结果相同。



#### 采用存储过程封装事务

> 因为性能影响，采用单线程串行执行的系统往往不支持交互式的多语句事务。应用程序必须提交整个事务代码作为存储过程（stored procedure）打包发送到数据库。

{% asset_img 交互式事务与存储过程的区别.png 交互式事务与存储过程的区别 %}



优点：

* 存储过程与内存式数据储存使得单线程上执行所有事务变得可行。

缺点：

* 在数据库中运行代码难以管理：与应用服务器相比，调试更加困难，版本控制与部署复杂，测试不便，并且不容易和指标监控系统集成。
* 数据库通常比应用服务器要求更高的性能。数据库中一个设计不好的存储过程要比同样低效的应用服务器代码带来更大的麻烦。



#### 分区

对于那些高写入需求的应用程序，单线程事务处理很容易称为严重的瓶颈。为了扩展到多个CPU核和多节点，可以对数据进行分区。

但是，对于跨分区的事务，数据库必须在设计的所有分区之间协调事务。存储过程需要跨越所有分区加锁执行，以确保整个系统的可串行化。

跨分区的事物具有额外的协调开销，其性能比单分区内要慢得多。



#### 串行执行小结

满足下面的条件，串行执行事务可以实现串行隔离：

* 事务必须简短而高效，否则一个缓慢的事务会影响到所有其他事务的执行性能。
* 仅限于活动数据集完全可以加载到内存的场景。有些很少访问的数据可能会被移到磁盘，但万一单线程事务需要访问它，就会严重拖累性能。
* 写入吞吐量必须足够低，才能在单个CPU核上处理；否则就需要采用分区，最好没有跨分区事务。
* 跨分区事务虽然也支持，但是占比必须很小。



### 两阶段加锁 two-phase locking

> 两阶段加锁（2PL）听起来和两阶段提交（2PC）很相近，但并不是同一个东西。



2PL不仅在并发写操作之间互斥，读取也会和修改产生互斥。这就是两阶段加锁和快照级别隔离（读写互不干扰）的区别。

因为2PL提供了串行化，所以它可以防止前面讨论的所有竞争条件，包括更新丢失和写倾斜。



#### 实现两阶段加锁

> 目前，2PL已经用于MySQL 和 SQL Server 中的“可串行化隔离”，以及DB2中的“可重复读隔离”

* 如果事务要读取对象，必须先以共享模式获得锁。
* 如果事务要修改对象，必须以独占模式获取锁。
* 如果事务首先读取对象，然后尝试写入对象，则需要将共享锁升级为独占锁。
* 事务获得锁之后，一直持有所直到事务结束（包括提交或中止）。

数据库会自动检测事务之间死锁情况，并强制中止其中一个，稍后由应用层重试。



#### 两阶段加锁的性能

> 其事务吞吐量和查询响应时间相比于其他弱隔离级别下降非常多

当一个事务还需要等待另一个事务时，那么最终的等待时间是没有上限的

如果事务由于死锁而被强行终止，应用层就必须从头重试。



#### 谓词锁 Predicate locks

类似于之前描述的共享/独占锁，而区别在于，它并不属于某个特定的对象，而是作用于**满足某些搜索条件**的所有查询对象。

* 事务A想要读取某些满足匹配条件的对象，它必须以共享模式获的查询条件的谓词锁。如果另一个事务B正持有任何一个匹配对象的互斥锁，那么A必须等到B释放锁之后才能继续执行查询。
* 如果事务A想要插入、更新或删除任何对象，则必须首先检查所有旧值和新值是否与现有的任何谓词锁匹配。如果事务B持有这样的谓词锁，那么A必须等到B完成提交后才能继续。

谓词锁甚至可以保护数据库中那些尚不存在但可能马上会被插入的对象。将两阶段加锁与谓词锁结合使用，数据库可以防止所有形式的写倾斜以及其他竞争条件，隔离变的真正可串行化。

缺点：

谓词锁性能不佳，如果活动事务中存在许多锁，那么检测匹配这些锁就变得非常耗时。



#### 索引区间锁 next-key locking

是一种简化的谓词锁，将其保护的对象扩大化。如果没有合适的索引可以施加区间锁，则数据库可以回退到对整个表施加共享锁。



### 可串行化的快照隔离 Serializable Snapshot Isolation

它提供了完整的可串行性保证，而性能相比于快照隔离损失很小。



#### 悲观与乐观的并发控制

两阶段加锁是一种典型的悲观并发控制机制。相比之下，可串行化的快照隔离（Serializable Snapshot Isolation, SSI）则是一种乐观并发控制。

如果系统还有足够的性能提升空间，且如果事物之间的竞争不大，乐观并发控制会比悲观方式高效很多。



#### 基于过期的条件做决定

安全起见，数据库假定对查询结果的任何变化都应使写事务失效。

数据库如何知道查询结果是否发生了改变呢？

1. 读取是否作用于一个过期的MVCC对象（读取之前已经有未提交的写入）
2. 检查写入是否影响即将完成的读取



#### 检测是否读取了过期的MVCC对象

{% asset_img 检测事务是否从MVCC快照中读取了旧值.png 检测事务是否从MVCC快照中读取了旧值 %}

**当事务提交时**，数据库会检查是否存在一些当初被忽略的写操作现在已经完成了提交，如果是则必须终止当前事务。

一定要等到提交是因为：

* 如果事务43是个只读事务，就不需要中止。事务43读取数据库时，数据库还不知道事务是否稍后有任何写操作
* 有可能事务42发生了中止或者还处于未提交状态，不一定读的就是过期值。





#### 检测写是否影响了之前的读

{% asset_img 检测事务是否修改了另一个事务查询结果.png 检测事务是否修改了另一个事务查询结果 %}

另一个事务尝试修改的时，首先检查索引，从而确定是否最近存在一些读目标数据的其他事物。



#### 可串行化快照隔离的性能

与两阶段加锁相比，可串行化快照隔离的一大优点是事务不需要等待其他事务所持有的锁。

事务中止的比例会显著影响SSI的性能表现。



## 小结



* 脏读
  * 客户端读到了其他客户端尚未提交的写人。读-提交以及更强的隔离级别可以防止脏读。
* 脏写
  * 客户端覆盖了另一个客户端尚未提交的写入。几乎所有的数据库实现都可以防止脏写。
* 读倾斜（不可重复读）
  * 客户在不同的时间点看到了不同值。快照隔离是最用的防范手段，即事务总是在某个时间点的一致性快照中读取数据。通常采用多版本井发控制（ MVCC ）来实现快照隔离。
* 更新丢失
  * 两个客户端同时执行读－修改－写入操作序列，出现了其中一个覆盖了另一个的写入，但又没有包含对方最新值的情况，最终导致了部分修改数据发生了丢失。快照隔离的一些实现可以自动防止这种异常，而另 一些则需要手动锁定查询结果 (SELECT FOR UPDATE ）。
* 写倾斜
  * 事务首先查询数据，根据返回的结果而作出某些决定，然后修改数据库 。当事务提交时，支持决定的前提条件已不再成立。只有可串行化的隔离才能防止这种异常。
* 幻读
  * 事务读取了某些符合查询条件的对象，同时另一个客户端执行写入，改变了先前的查询结果。快照隔离可以防止简单的幻读，但写倾斜情况则需要特殊处理，例如采用区间范围锁。

弱隔离级别可以防止上面的某些异常，只有可串行化的隔离可以防止所有这些问题。实现可串行化隔离有以下几种：

* 严格串行执行事务
  * 如果每个事务的执行速度非常快，且单个CPU核可以满足事务的吞吐量要求，严格串行执行是一个非常简单有效的方案。
* 两阶段加锁
  * 几十年来，这一直是实现可串行化的标准方式，但还是有很多系统出于性能原因而放弃使用它。
* 可串行化的快照隔离
  * 一种最新的算法，可以避免前面方法的大部分缺点。它秉持乐观预期的原则， 允许多个事务并发执行而不互相阻塞；仅当事务尝试提交时，才检查可能的冲突，如果发现违背了串行化，则某些事务会被中止。



# 第八章：分布式系统的挑战

本章节对分布式系统可能出现的故障做了一个全面的总结。故障可能来自网络，时钟时序问题。



## 不可靠的网络

处理网络的问题通常采用超时机制：在等待一段时间之后，如果仍然没有收到回复则选择放弃，并且认为响应不会到达。

### 检测故障

* 负载均衡器需要避免向已失效的节点继续分发请求
* 对于主从复制的分布式数据库，如果主节点失败，需要将某个从节点提升为主节点。



### 超时与无限期的延迟

没有一个标准的设置超时时间的值。

异步网络理论上的延迟无限大（即使尽力发送数据包，但数据包到达时间并没有上确界），多数服务端也无法保证在给定的某个时间内一定完成请求处理（参阅本章后面的“响应时间保证”）。如果超时设置太小，只需要一个短暂的网络延迟尖峰就会导致包超时进而将系统标记为失效。



#### 网络拥塞与排队

更好的做法是， 超时设置并不是一个不变的常量，而是持续测量响应时间及其变化（抖动），然后根据最新的响应时间分布来自动调整。



### 同步与异步网络

#### 电路交换 vs. 分组交换

电路方式总是预留固定带宽，电路建立之后其他人无法使用；TCP连接的数据包则会尝试使用所有可用的网络带宽。

以太网和IP都是基于分组交换协议，这种协议注定受到排队的影响，从而导致网络延迟不确定， 在这些协议里完全没有电路的概念。

数据中心网络和互联网采用分组交换是因为无法事先确定带宽，只希望尽快完成。对于突发数据的传输，电路网络无法充分利用网络容量。相比之下，TCP动态调整传输速率则可以充分利用所有可用的网络容量。



## 不可靠的时钟

### 单调时钟与墙上时钟

#### 墙上时钟

> 墙上时钟根据某个日历返回当前的日期与时间。

* Linux的clock_gettime
* Java中的System.currentTimeMillis()

墙上时钟可以与NTP同步。NTP（Network Time Protocol）是用来同步网络设备的时间协议。

#### 单调时钟

单调时钟更适合测量持续时间段（时间间隔）。可以在一个时间点读取单调时钟的值，完成某项工作，然后再次检查时钟。时钟值之间的差值即两次检查之间的时间间隔。



### 时钟同步与准确性

单调时钟不需要同步，但是墙上时钟需要根据NTP服务器或其他外部时间源做必要的调整。

可能会出现一下的一些问题：

* 计算机中的石英钟不够精确，存在漂移现象（运行速度会加快或减慢）
* 如果时钟与NTP服务器的时钟差别太大，可能会出现拒绝同步，或者本地时钟将被强制重置（时间突然倒退或突然跳跃的现象）。
* 可能会与NTP服务器链接失败，可能会很长一段时间没有留意到错误配置最终导致同步失败。
* NTP同步会受限于当时的网络环境。
* 闰秒会产生一个59秒或者61秒的现象，可能会使一些对闰秒毫无防范的系统出现混乱。
* 在虚拟机中，由于硬件时钟也是被虚拟化的，这对需要精确计时的应用程序提出了额外的挑战。
* 运行在未完全可控的设备（移动设备或嵌入式设备）上，需要留意不能完全相信设备上的硬件时钟。



### 依赖同步的时钟

如果应用需要精确同步的时钟，最好仔细监控所有节点上的时钟偏差。如果某个节点的时钟漂移超出上限，应将其宣告为失效，并从集群中移除。

#### 时间戳与时间顺序

{% asset_img 跨节点时间排序.png 跨节点时间排序 %}

客户端B的写入比客户端A写入要晚，但是B写入的时间戳却更早

这种冲突解决策略被称为最后写入获胜（Last Write Win, LWW），它的根本问题在于：

* 数据库写入可能会奇怪地丢失：明明后续发生的写操作却没法覆盖另一个较早的值，原因是后者节点的时钟太快了。
* LWW无法区分连续快速发生的连续写操作和并发写入（每个写操作都不依赖于其他写 ）
* 由于时钟精度的限制（例如毫秒级），两个节点可能各自独立产生了完全相同的时间戳。



> 我们很难利用NTP时钟同步来做到极高的精度来避免这种错误



#### 时钟的置信区间

> 我们不应该将时钟读数视为一个精确的时间点，而更应该视为带有置信区间的时间范围。



#### 全局快照的同步时钟

常见的快照隔离实现中需要单调递增事务ID。如果写入发生在快照之后（即写入具有比快照更大的事务ID），那么该写入对于快照不可见。在单节点数据库上，一个简单的计数器足以生成事务ID。

但是，当数据库分布在多台机器上（可能跨越多个数据中心）时，由于需要复杂的协调以产生全局的、单调递增的事务ID（跨所有分区）。考虑到大量、频繁的小数据包，在分布式系统中创建事务ID通常会引入瓶颈。



##### Google Spanner

Google Spanner采用以下思路来实现跨数据中心的快照隔离。它根据TrueTime API返回的时钟置信区间，并基于以下观察结果：如果有两个置信区间，每个置信区间都包含最早和最新可能的时间戳（ *A*=[ *A<sub>earliest</sub> , A<sub>latest</sub>* ] 和 *B* =[ *B<sub>earliest</sub> , B<sub>latest</sub>* ] ），且这两个区间没有重叠（即 *A<sub>earliest</sub> < A<sub>latest</sub>* < *B<sub>earliest</sub>* < *B<sub>latest</sub>* ），那么可以断定*B*一定发生在*A*之后。只有发生了重叠，*A*和*B*发生顺序才无法明确。



为了确保事务时间戳反映因果关系， Spanner在提交读写事务之前故意等待置信区间的长度。这样做的目的是，确保所有读事务要足够晚才发生，避免与先前的事务的置信区间产生重叠。



### 进程暂停

假设数据库每个分区只有一个主节点，只有主节点可以接受写入。那么其他节点该如何确信该主节点没有被宣告失效，可以安全地写入呢？

> 一种思路是主节点从其他节点获得一个租约（lease），类似一个带有超时的锁。某一个时间只有一个节点可以拿到租约，某节点获得租约之后，在租约到期之前，它就是这段时间内的主节点。为了维持主节点的身份，节点必须在到期之前定期去更新租约 。如果 节点发生了故障， 则续约失败，这样另一个节点到期之后就可以接管。



```java
while (true) {
  request = getIncomingRequest();
  
  if (lease.expiryTimeMillis - System.currentTimeMillis() < 10000) {
    lease = lease.renew();
  }
  
  if (lease.isValid()) {
    process(request);
  }
}
```

可能存在的问题：

1. 依赖于同步时钟：lease到期时间由另一台机器所设置，并和本地时钟进行比较。
2. ```System.currentTimeMillis()```与请求处理`process(request)`间隔时间不可预测。如果发生了线程暂停的情况，将会出现两个节点同时持有租期处理的情况。



发生线程暂停的原因有很多：

* 垃圾回收机制可能会导致所有正在运行的线程暂停几分钟。
* 在虚拟化的环境中，可能会暂停虚拟机然后继续。
* 用户关闭了笔记本电脑或休眠也有可能导致暂停。
* 当操作系统执行线程上下文切换时，或者虚拟机管理程序切换到另一个虚拟机时，正在运行的线程可能会在代码的任意位置被暂停。
* 应用程序执行同步磁盘操作，则线程可能暂停并等待磁盘I/O完成。
* 如果操作系统配置了基于磁盘的内存交换分区， 内存访问可能触发缺页中断， 进而需要从磁盘中加载内存页。




> 分布式系统中的一个节点必须假定，执行过程中的任何时刻都可能被暂停相当长一段时间。暂停期间，整个集群的其他部分都在照常运行，甚至会一直将暂停的节点宣告为故障节点。



#### 响应时间保证

> 实时系统：软件有一个必须做出相应的上限。

提供实时保证需要来自软件栈的多个层面支持：

* 一个实时操作系统（real-time operating system, RTOS），保证进程在给定的间隔内完成CPU时间片的调度分配
* 库函数也必须考虑最坏的执行时间
* 动态内存分配很可能要受限或者完全被禁止

对于大多数服务器端数据处理系统来说，实时性保证并不经济或者不合适。因此，现在这些运行在非实时环境下的系统就得承受如进程暂停、 时钟不稳定等困扰。



##### 调整垃圾回收的影响

* 把GC暂停视为节点的一个计划内的临时离线，当节点启动垃圾回收时，通知其他节点来接管客户端的请求。
* 系统可以提前为前端应用发出预警，应用会等待当前请求完成，但停止向该节点发送新的请求，这样垃圾回收可以在无干扰的情况下更加高效运行。
* 只对短期对象执行垃圾回收，然后在其变成长期存活对象之前，采取定期重启的策略从而避免对长期存活对象执行全面回收。





## 知识，真相与谎言



### 真相由多数决定

节点不能根据自己的信息来判断自身状态。由于节点可能随时会失效，可能会暂停-假死，甚至最终无法恢复，因此，分布式系统不能完全依赖与单个节点。

目前，许多分布式算法都依靠法定票数，即在节点之间进行投票。任何决策都需要来自多个节点的最小投票数，从而减少对特定节点的依赖。



#### 主节点和锁

> 在分布式系统实现时需要额外注意：即使某个节点自认为它是“唯一的那个”，但不一定获得了系统法定票数的同意！

{% asset_img 分布式锁的不正确实现.png 分布式锁的不正确实现 %}



#### Fencing令牌

我们假设每次锁服务在授予锁或租约时，还会同时返回一个fencing令牌，该令牌每授予一次就会递增。要求客户端每次向存储系统发送写请求时，都必须包含所持有的fencing令牌。

{% asset_img 递增fencing令牌.png 递增fencing令牌 %}

存储服务器由于记录了最近已经完成了更高令牌号，因此拒绝令牌号33的写请求。



### 拜占庭故障 Byzantine Faults

当节点故意发送错误的或者破坏性的响应，就被称为拜占庭故障。在这样不信任的环境中需要达成共识的问题也被称之为拜占庭将军问题。如果某个系统中即使发生部分节点故障，甚至不遵从协议，或者恶意攻击、干扰网络，但仍可继续正常运行，那么我们称之为拜占庭式容错系统。

解决拜占庭容错的系统协议异常复杂，而容错的嵌入式系统还依赖与硬件层面的支持。因为在绝大多数服务器端数据系统中，部署拜占庭容错解决方案基本不太可行。



### 理论系统模型与现实

在计时方面，有常见的三种模型：

* 同步模型
  * 同步模型假定有上届的网络延迟，有上届的进程暂停和由上届的时钟误差。
* 部分同步模型
  * 部分同步意味着系统在大多数情况下像一个同步系统一样运行，但有时会超出网络延迟，进程暂停和时钟漂移的预期上届。
* 异步模型
  * 在这个模型中，一个算法不会对时机作任何的假设，甚至里面根本没有时钟（也就没有超时机制）。



除了时机之外，我们还需要考虑节点失效。

* 崩溃-终止模型
  * 算法假设一个节点只能以一种方式发生故障，即遭遇系统崩溃。这意味着节点可能在任何时候突然停止响应，且该结点以后永远消失，无法恢复。
* 崩溃-恢复模型
  * 节点可能会在任何时候发生崩溃，且可能会在一段（未知的）时间之后得到恢复并再次响应。在崩溃－恢复模型中，节点上持久性存储（即非易失性存储）的数据会在崩溃之后得以保存，而内存中状态可能会丢失。
* 拜占庭失效模型
  * 节点可能发生任何事情，包括试图作弊和欺骗其他节点。







## 小结

分布式系统中可能发生的各种典型问题：

* 当通过网络发送数据包时， 数据包可能会丢失或者延迟； 同样，回复也可能会丢失或延迟。所以如果没有收到回复，并不能确定消息是否发送成功。
* 节点的时钟可能会与其他节点存在明显的不同步（尽管尽最大努力设置了NTP服务器），时钟还可能会突然向前跳跃或者倒退 ，依靠精确的时钟存在一些风险，没有特别简单的办法来精确测量时钟的偏差范围。
* 进程可能在执行过程中的任意时候遭遇长度未知的暂停（ 一个重要的原因是垃圾回收），结果它被其他节点宣告为失效毫无所知。




为了容错，需要先检测错误：

多数系统没有检测节点是否发生故障的准确机制，因此分布式算法更多依靠超时来确定远程节点是否仍然可用。



检测到错误之后：

信息从一个节点流动到另一个节点只能是通过不可靠的网络来发送。单个节点无法安全的做出任何决策，而是需要多个节点之间的共识协议，井争取达到位定票数。



虽然网络、时钟和进程的不可靠性不是不可避免的自然规律，但代价昂贵，且硬件资源利用率很低。除了安全关键场景，目前绝大多数都选择了低成本。



# 第九章 一致性与共识

这一章，我们将主要研究解决共识问题的相关算法。

## 一致性保证

大多数多副本数据库都至少提供了最终一致性。不一致的现象是暂时的，最终会达到一致。

* 首先介绍线性化，是最强的一致性模型

* 探讨分布式系统中事件顺序问题，主要是因果关系和全局顺序。

* 在“分布式事务与共识”，将探索如何让自动提交分布式事务，并最终解决共识问题。

  

## 可线性化 Linearizability

> 让数据库看起来对外只提供“单个副本”的假象。

可线性化=原子一致性=强一致性=linearizability=atomic consistency=strong consistency=immediate consistency=external consistency



### 如何达到线性化

{% asset_img 线性化1.png 线性化1 %}

与写操作有时间重叠的任何读取操作则可能返回0或者1，这是因为读写之间存在并发，无法确切知道在执行读取时，写入是否已经生效。

{% asset_img 线性化2.png 线性化2 %}

一旦某个读操作返回了新值，之后所有的读（包括相同或不同的客户端）都必须返回新值。



> 一旦新值被写入或读取，所有后续的读都看到的是最新的值，直到被再次覆盖。



### 可线性化 vs. 可串行化

* 可串行化
  * 可串行化是事务的隔离属性，其中每个事务可以读写**多个对象**。它用来确保事务执行的结果与串行一致，即使串行执行的顺序可能与事务实际执行顺序不同。
* 可线性化
  * 可线性化是读写寄存器（**单个对象**）的最新值保证。它并不要求将操作组合到事务中，因此无法避免写倾斜等问题，除非采取其他额外措施。

数据库可以同时支持可串行化与线性化。但是可串行化的快照隔离（SSI）则不是线性化的：他可以从一致性快照中读取以避免读、写之间的竞争。一致性快照的要点在于它里面不包括快照点创建时刻之后的写入数据，因此从快照读取肯定不满足线性化。



### 线性化的依赖条件

#### 加锁与主节点选举

主从复制的系统需要确保有且只有一个主节点，否则会 split brain。选举新的主节点常见的方法是使用锁，不管锁具体如何实现，它必须满足可线性化：所有节点都必须同意哪个节点持有锁，否则就会出现问题。



#### 约束与唯一性保证

如果要在写入数据时强制执行这些约束，则也需要线性化。



#### 跨通道的时间依赖

线性化违例之所以被注意到，是因为系统中存在其他的通信渠道。



例：用户可以上传照片，有一个后台的进程将照片调整为更低的分辨率以方便快速下载

{% asset_img 图像存储.png 图像存储 %}

Web服务器并不会把照片直接放在队列中，照片会先写入文件存储服务，当写入完成后，把调整的命令放入队列。如果没有可线性化的保证，消息队列可能比存储服务内部的复制执行更快，这样调整模块可能会读取到旧数据。



出现这个问题是因为Web服务器和调整模块之间存在两个不同的通信信道：文件存储器和消息队列。



### 实现线性化系统

* 主从复制（部分支持线性化）
  * 只有主节点承担数据写入，从节点则在各自节点上维护数据的备份副本。
  * 如果从主节点或者同步更新的从节点上读取，则可以满足线性化。
  * 但并非每个主从复制的具体数据库实例都是可线性化的，主要是因为他们可能采用了快照隔离的设计，或者实现时存在并发方面的bug。
* 共识算法（可线性化）
  * 
* 多主复制（不可线性化）
  * 它们同时在多个节点上执行并发写入，并将数据一步复制到其他节点。因此它们可能会产生冲突的写入。
* 无主复制（可能不可线性化）



### 线性化的代价

基于多主复制的数据库，每个数据中心都可以继续正常运行：

> 由于从一个数据中心到另一个数据中心的复制是异步，期间发生的写操作都暂存在本地队列，等网络恢复之后再继续同步。



而基于主从复制的数据库，则主节点肯定位于其中的某一个数据中心。所有写请求和线性化读取都必须发送给主节点。因此，对于这样的主从复制系统，数据中心之间的网络一旦中断，连接到从数据中心的客户端无法再联系上主节点，也就无法完成任何数据库写入和线性化。



#### CAP理论

CAP-*Consistency, Availablity, Partition tolerance* 代表的是一种取舍的思路。



正式定义的CAP定理范围很窄，它只考虑了一种一致性模型（即线性化）和一种故障（网络分区，节点仍处于活动状态但相互断开），而没有考虑网络延迟、节点失败或其他需要折中的情况。



#### 可线性化与网络延迟

现代多核CPU上的内存甚至就是非线性化。每个CPU核都有自己独立的cache和寄存器。内存访问首先进入cache系统，所有修改默认会异步地刷新到主存。但是，这就导致出现了多个数据副本（一个在主存，另外几个在不同级别的cache中），而副本更新是异步方式，无法保证线性化。

> 之所以放弃线性化的原因就是性能，而不是为了容错。



## 顺序保证

### 顺序与因果关系

因果关系对所发生的事件施加了某种排序：发送信息先于收到信息；问题的出现在答案之前。

> 如果系统服从因果关系所规定的顺序，我们称之为因果一致性。



#### 因果顺序并非全序

全序关系支持任何两个元素之间进行比较，即对于任意两个元素，总是可以指出哪个更大，哪个更小。

对于不可比较的集合，我们称之为偏序。



* 可线性化
  * 在一个可线性化的系统中，存在全序操作关系。
  * 对于任意两个操作，我们总是可以指出哪个操作在先。
* 因果关系
  * 如果两个事件是因果关系，那么这两个事件可以被排序
  * 而并发的事件则无法排序比较。
  * 因果关系至少可以定义为偏序，而非全序。

> 在可线性化数据存储中不存在并发操作，一定有一个时间线将所有操作都全序执行。



#### 可线性化强于因果一致性

可线性化一定意味着因果关系：任何可线性化的系统都将正确地保证因果关系。

> 因果一致性可以认为是，不会由于网络延迟而显著影响性能，又能对网络故障提供容错的最强的一致性模型。



### 序列号排序

可以使用序列号或时间戳来排序事件。每一个操作都有唯一的顺序号，并且总是可以通过比较来确定哪个更大。

在主从复制数据库中，复制日志定义了与因果关系一致的写操作全序关系。主节点可以简单地为每个操作递增某个计数器，从而为复制日志中的每个操作复制一个单调递增的序列号。



#### 非因果序列发生器

如果系统不存在这样唯一的主节点：

* 每个节点都独立产生自己的一组序列号。
  * 如果有两个节点，则一个节点只生成奇数，而另一个节点只生成偶数。
  * 每个节点可能有不同的处理速度。
* 可以把墙上时间戳信息附加到每个操作上。
  * 物理时钟的时间戳会收到时钟偏移的影响，也可能导致与实际因果关系不一致。
* 可以预先分配序列号的区间范围。
  * 一个后发的操作可能拿到一个之前的区间



#### Lamport时间戳

这个时间戳可以产生与因果关系一致的序列号。

{% asset_img Lamport时间戳.png Lamport时间戳 %}

> 给定两个Lamport时间戳，计数器较大那个时间戳大；如计数器数值正好相同，则节点ID越大，时间戳越大

**每个节点以及每个客户端都跟踪迄今为止所见到的最大计数器值，并在每个请求中附带该最大计数器值。**当节点收到某个请求（或者回复）时，如果发现请求内嵌的最大计数器值大于节点自身的计数器值，则它立即把自己的计数器修改为该最大值。这样就可以保证后发生的请求得到更大的时间戳。



#### 时间戳排序依然不够

只有在收集了所有的请求信息之后，才能清楚这些请求之间的全序关系。要想知道什么时候全序关系已经确定就需要之后的“全序关系广播”。



### 全序关系广播

> 全序关系广播通常指节点之间交换消息的某种协议。

* 可靠发送
  * 没有消息丢失，如果消息发送到了某一个节点，则它一定要发送到所有节点
* 严格有序
  * 消息总是以相同的顺序发送给每个节点



#### 使用全序关系广播

* 数据库复制需要全序关系广播
  * 如果每条消息代表数据库写请求，并且每个副本都按相同的顺序处理这些写请求，那么所有副本可以保持一致。
* 可以使用全序关系广播来实现可串行化事务
  * 如果每条消息表示一个确定性事务并且作为存储过程来执行，且每个节点都遵从相同的执行顺序，那么可以保证数据库各分区以及个副本之间的一致性
* 顺序在发送信息时已经确定
  * 如果消息发送成功，节点不允许追溯地将某条消息插入到先前的某个位置上



#### 采用全序关系广播实现线性化存储

全序关系广播 vs. 可线性化

* 全序关系广播
  * 基于异步模型
  * 保证消息以固定的顺序可靠地发送，但是不保证消息何时发送成功（某个接受者可能明显落后于其他接受者）
* 可线性化
  * 读取时保证能够看到最新的写入值



通过使用全序关系广播以追加日志的方式来实现线性化的原子比较-设置操作

1. 在日志中追加一条消息，并指明想要的用户名
2. 读取日志，将其广播给所有节点，并等待回复
3. 检查是否有任何消息声称该用户名已被占用。如果第一条这样的回复来自于当前节点，那么就成功获得该用户名，可以提交该获取声明并返回给客户端。

**此过程可以保证线性化写入，但它无法保证线性化读取，即从异步日志更新的存储中读取数据时，可能是旧值。**



#### 采用线性化存储实现全序关系广播

同样可以假定已有了线性化存储，在其上构建全序关系广播。

假设有一个线性化的寄存器来存储一个计数，然后使其支持原子自增-读取操作或者原子比较-设置操作

对于每个要通过全序关系广播的消息，原子递增并读取该线性化的计数，然后将其作为序列号附加到消息中。接下来，将消息广播到所有节点（如果发生丢失，则重新发送），而接受者也严格按照序列化来发送回复消息。



## 分布式事务与共识

共识的不可能性：

FLP(Fisher, Lynch, and Paterson)表明如果结点存在崩溃的风险，则不存在总是能够达成共识的稳定算法。



### 原子提交与两阶段提交

#### 从单节点到分布式的原子提交

**单节点**

* 当客户端请求数据库节点提交事务时，数据库首先使事务的写入持久化。

* 把提交记录追加写入到磁盘的日志文件中
  * 如果数据库在该过程中间发生了崩溃，那么当节点重启后，事务可以从日志中恢复；
  * 如果在崩溃之前提交记录已成功写入磁盘，则认为事务已安全提交；
  * 否则，回滚该事务的写入



**多节点**

向所有节点简单地发送一个提交请求，然后各个节点独立执行事务提交是不够的。如果一部分节点提交了事务，而其他节点却放弃了事务，节点之间就会变得不一致。



#### 两阶段提交

> 两阶段提交是一种在多节点之间实现事务原子提交的算法，用来确保所有节点要么全部提交，要么全部中止。

{% asset_img 两阶段提交.png 两阶段提交 %}



区分**两阶段提交**（2PC）和**两阶段加锁**（2PL）。2PC在分布式数据库中负责原子提交，而2PL则提供可串行化的隔离。



2PC引入了新组件：协调者（也称为事务管理器）。协调者通常实现为共享库，运行在请求事务相同进程中，但也可以是单独的进程或服务。



当应用程序准备提交事务时 ，协调者开始阶段1：发送一个准备请求到所有节点，询问他们是否可以提交。

* 如果所有参与者回答“是”，表示他们已经准备好提交，那么协调者接下来在阶段2会发出提交请求，提交开始实际执行。
* 如果有任何参与者回复“否”，则协调者在阶段2中向所有节点发送放弃请求。



#### 系统的承诺

两阶段提交的流程：

1. 当应用程序启动一个分布式事务时，它首先向协调者请求事务ID。该ID全局唯一。
2. 应用程序在每个参与节点上执行单节点事务，并将全局唯一事务ID附加到事务上。此时，读写都是在单节点内完成。如果在这个阶段出现问题（例如节点崩溃或请求超时），则协调者和其他参与者都可以安全中止。
3. 当应用程序准备提交时，协调者向所有参与者发送准备请求，并附带全局事务ID。如果准备请求有任何一个发生失败或者超时，则协调者会通知所有参与者放弃事务。
4. 参与者在收到准备请求后，确保在任何情况下都可以提交事务，包括安全地将事务数据写入磁盘，并检查是否存在冲突或约束违规。一旦向协调者回答“是”，节点就承诺会提交事务。
5. 当协调者受到所有准备请求的答复时，就是否提交（或放弃）事务要做出明确的决定。协调者把最后的决定写入到磁盘的事务日志中，防止稍后系统崩溃，并可以恢复之前的决定。这个时刻称为**提交点**
6. 协调者的决定写入磁盘后，接下来向所有参与者发送提交（或放弃）请求。如果此请求出现失败或超时，则协调者必须一直重试，直到成功为止。



> 参与者投票“是”，它作出了肯定提交的承诺；协调者作出了提交的决定。这两个承诺确保了2PC的原子性。



#### 协调者发生故障

{% asset_img 协调者发生故障.png 协调者发生故障 %}

如果在决定到达之前，出现协调者崩溃或网络故障，则参与者只能无奈等待。此时参与者处在一种不确定的状态。

2PC能够顺利完成的唯一方法是等待协调者恢复。这就是为什么协调者必须在向参与者发送提交（或中止）请求之前要将决定写入磁盘的事务日志；等协调者恢复之后，通过读取事务日志来确定所有未决的事务状态。



### 实践中的分布式事务

#### Exactly-once 消息处理

如果消息发送或数据库事务任何一个发生失败，则两者都需中止，消息队列可以在稍后再次重传消息。因此，通过自动提交消息





### 支持容错的共识

> 共识是让几个节点就某项提议达成一致

共识算法必须满足的性质：

* 协商一致性 Uniform agreement
  * 所有的节点都接受相同的决议。
* 诚实性 Integrity
  * 所有的节点不能反悔，即对一项提议不能有两次决定。
* 合法性 Validity
  * 如果决定了值v，则v一定是由某个节点所提议的。
* 可终止性 Termination
  * 节点如果不崩溃则最终一定可以达成协议
  * 引入了容错的思想，重点强调了一个共识算法不能原地空转，永远不做事情。



所有采取等待节点恢复的算法都无法满足终止性，特别是2PC不符合可终止性要求。事实上，可以证明任何共识算法都需要至少大部分节点正确运行才能确保终止性。而这个多数就可以安全地构成quorum。



> quorum机制：
>
> 是一种分布式系统中常用的，用来保证数据冗余和最终一致性的投票算法，其主要数学思想来源于鸽巢原理。



#### 共识算法与全序广播

最著名的容错式共识算法包括VSR, Paxos, Raft和Zab.

> 全序关系广播的要点是，消息按照相同的顺序发送到所有节点，有且只有一次。如果仔细想想，这其实相当于进行了多轮的共识过程：在每一轮，节点提出他们接下来想要发送的消息，然后决定下一个消息的全局顺序。



#### 主从复制与共识

如何选择主节点将会影响我们是否去考虑共识问题。如果主节点是由运营人员手动选择和配置的，那基本上就是一个独裁性质的”一致性算法“：只允许一个节点接受写入，如果该结点发生故障，系统将无法写入，直到操作人员再手动配置新的节点称为主节点。但这个方案不满足共识的可终止性。



存在一个问题：

我们需要共识算法选出一位主节点。但是，如果这里描述的共识算法实际上是全序关系广播，且全序关系广播很像主从复制，但主从复制现在有需要选举主节点。



#### Epoch和Quorum

目前所讨论的所有共识协议在其内部都使用了某种形式的主节点，虽然主节点并不是固定的。相反，他们都采用了一种弱化的保证：协议定义了一个epoch number，并保证在每个世代（对应于Raft中的term）里，主节点是唯一确定的。



后面这个部分讲的其实就是Raft的基础原理。存在两轮不同的投票：首先是投票决定谁是主节点，然后是主节点的提议进行投票。





#### 共识的局限性

* 采用异步复制，原因正是为了更好的性能
* 多数共识算法假定一组固定参与投票的节点集，这意味着不能动态添加或删除节点
* 共识系统通常依靠超时机制来检测节点失效。在网络延迟高度不确定的环境中，特别是那些跨区域分布的系统，经常由于网络延迟的原因，导致节点错误地认为主节点发生了故障。



### 成员与协调服务

ZooKeeper 和 etcd 主要针对保存少量、可完全载入内存的数据（虽然它们最终仍要写入磁盘以支持持久性）而设计，所以不要用他们保存大量的数据。



#### 节点任务分配

以下场景可以借助ZooKeeper中的原子操作，ephemeral nodes和通知机制来实现：

* 如果系统有多个流程或服务的实例，并且需求其中一个实例充当主节点；而如果主节点失效，由其他某个节点来接管。
* 对于一些分区资源（可以是数据库，消息流，文件存储等），需要决定将哪个分区分配给哪个节点。





#### 服务发现

ZooKeeper, etcd和Consul还会用于服务发现。

> 每当节点启动时将其网络端口信息向ZooKeeper等服务注册，然后其他人只需向ZooKeeper的注册表中询问即可。





#### 成员服务

> 成员服务用来确定当前哪些节点处于活动状态并属于集群的有效成员







## 小结



























