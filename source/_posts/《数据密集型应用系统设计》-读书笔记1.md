---
title: 《数据密集型应用系统设计》- 读书笔记1
date: 2021-01-13 10:05:51
tags: [读书笔记, 数据密集型应用系统设计]
categories: 分布式系统
---

[TOC]



# 第二章 数据模型与查询语言

## 关系模型与文档模型

> 数据被组织成关系（relations），在SQL中称为表（table），其中每个关系都是元组（tuples）的无序集合（在SQL中称为行）。



### NoSQL的诞生

采用NoSQL数据库有这样几个驱动因素 ，包括 ：

* 比关系数据库更好的扩展性需求，包括支持超大数据集或超高写入吞吐量。

* 普遍偏爱免费和开源软件而不是商业数据库产品 。

* 关系模型不能很好地支持一些特定的查询操作。

* 对关系模式一些限制性感到沮丧，渴望更具动态和表达力的数据模型。



### 对象-关系不匹配

大多数开发都采用面向对象的编程语言，如果数据存储在关系表中，那么应用层代码中的对象与表、行和列的数据库模型之间需要一个笨拙的转换层。

Object-relational mapping(ORM) 对象-关系映射

对于像简历这样的数据结构，它主要是一个自包含的文档（document），因此用JSON表示非常适合。面向文档的数据库（MongoDB, RethinkDB, CouchDB, Espresso）都支持该数据模型。



### 文档数据库是否在重演历史？

最早的计算机数据库系统是IBM信息管理系统。IMS采用了相当简单的数据模型，称为层次模型（类似JSON，它将所有数据表示为嵌套在记录中的记录）。IMS可以很好地支持一对多关系中，但是它支持多对多关系则有些困难，而且不支持联结。为了解决层次模型的局限性，之后提出了关系模型（relation model，后来演变成SQL）和网络模型（network model）



#### 网络模型

在层次模型的树结构中，每个记录只有一个父节点；而在网络模型中，一个记录可能有多个父结点。访问路记录的唯一方法是选择一条始于根记录的路径，并沿着相关链接依次访问。

在20世纪70年代，尽管手动路径选择能够最有效地利用当时非常有限的硬件资源，但最大的问题在于它们使查询和更新数据库变得异常复杂而没有灵活性。



#### 关系模型

关系模型所做的则是定义了所有数据的格式：关系（table）只是元组（tuple）的集合。没有复杂的嵌套结构，也没有复杂的访问逻辑。



#### 文档数据库的比较

文档数据库是某种方式的层次模型：即在其父记录中保存了嵌套记录，而不是存储在单独的表中。



### 关系数据库与文档数据库现状

支持文档数据模型的主要论点是模式灵活性，由于局部性而带来较好的性能 ，对于某些应用来说，它更接近于应用程序所使用的数据结构。关系模型则强在联结操作、多对一和多对多关系更简洁的表达上，与文档模型抗衡。



**如果应用数据具有类似文档的结构（即一对多关系树，通常一次加载整个树） ， 那么使用文档模型更为合适。而关系型模型则倾向于某种数据分解，它把文档结构分解为多个表，有可能使得模式更为笨重，以及不必要的应用代码复杂化。**





## 数据查询语言





## 图状数据模型





# 第三章 数据存储与检索

## 数据库核心：数据结构

适当的索引可以加速度取查询，但每个索引都会减慢写速度

### 哈希索引

假设数据存储全部采用追加式文件组成。

> 保存内存中的hash map, 把每个键一一映射到数据文件中特定的字节偏移量，这样就可以找到每个值的位置。

Bitcask （Riak 中的默认存储引擎）就是采用哈希索引的。它非常适合每个键的值频繁更新的场景。



如何避免最终用尽磁盘空间？

> 我们可以将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。然后可以在这些段上执行压缩，在日志中丢弃重复的键，并且只保留每个键最近的更新。



#### 需要考虑的问题

* 文件格式
  * csv 不是日志的最佳格式，应该使用二进制的格式，首先以字节为单位来记录字符串的长度，之后再跟上原始字符串。
* 删除记录
  * 如果要删除一个键和它关联的记录，在数据文件中追加一个tag。合并日志的时候，一旦发现tag，则会丢弃这个已经删除键的值。
* 崩溃恢复
  * 因为hash map是存在内存中的，数据库重新启动之后会丢失。Bitcask 通过将每个段的hash map的快照存储在磁盘上，可以更快的加载到内存中，以此加快恢复速度。
* 部分写入的记录
  * Bitcask 文件包括校验值，这样可以发现损坏部分并丢弃。
* 并发控制
  * 因为写入以严格的先后顺序追加到日志中，通常的实现选择是只有一个写线程。数据文件段是追加的，并且是不可变的，所以他们可以被多个线程同时读取。

#### 局限性

* 因为hash map 必须放在内存中，如果一旦有大量的键，就需要在磁盘维护hash map，这会导致整体的性能下降。
* 区间查询效率不高。

### SSTables和LSM-Tree

#### SSTables

> 要求每个存储段的key-value对的顺序按键排序。要求每个键在合并的段文件中只能出现一次。

>SSTable 是一个**持久化的、有序的、不可变的**映射表（map），其中的**键和值都可以 是任意字节字符串**。它提供了按 key 查询和对指定的 key range 进行遍历的操作。

SSTable相比哈希索引，具有优点：

* 合并段更加简单高效，即使文件大于可用内存
* 在文件中查找特定的键时，不再需要在内存中保存所有键的索引。仍然需要一个内存索引来记录某些键的偏移，但它可以是稀疏的。

{% asset_img SSTable及其内存中的索引.png SSTable及其内存中的索引 %}



##### 从SSTables到LSM-Tree

> 基于合并和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎。

LSM Tree的树节点可以分为两种，保存在内存中的称之为MemTable， 保存在磁盘上的称之为SSTable。



##### 构建和维护SSTables

* 当写入时，将其添加到内存中的平衡树数据结构中。这个内存中的树有时被称为内存表。
* 当内存表大于某个阈值时，将其作为SSTable文件写入磁盘。由于树已经维护了按键排序的key-value对，写磁盘可以比较高效。新的SSTable文件成为数据库的最新部分。当SSTable写磁盘的同时，写入可以继续添加到一个新的内存表实例。
* 处理读请求时，首先尝试在内存表中查找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件......
* 后台进程周期性的执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值。

LevelDB 和 RocksDB 使用的就是上面这段算法。



不同的策略会影响甚至决定SSTables压缩和合并时的具体顺序和时机。

* LevelDB和RocksDB使用分层压缩
  * 键的范围分裂成多个更小的SSTables，旧数据被移动到单独的“层级”。
* HBase使用大小分级
  * 较新的和较小的SSTables 被连续合并到较旧和较大的SSTables
* Cassandra则同时支持这两种压缩。



LSM-Tree 的基本思想：

> 保存在后台合并的一系列SSTable

[LSM-Tree初探](https://zhuangzhuang131419.github.io/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/)

### B-Tree

B-Tree 已经比较熟悉它的基本原理了，这里讲一些新的收获。

> B-Tree 将数据库分解成固定大小的块或页，页是内部读/写的最小单元。每个页面都可以使用地址或位置进行标识，不过是指向磁盘地址，而不是内存。



#### B-Tree 可靠

* 预写日志（write-ahead log, WAL）
  * 这是一个仅支持追加修改的文件，每个B-Tree的修改必须先更新 WAL 然后再修改树本身的页。当数据库在崩溃后需要恢复时，该日志用于将B-Tree恢复到最近一直的状态。

* 原地更新页
  * 如果多个线程要同时访问B-Tree，则需要注意并发控制，否则线程可能会看到树处于不一致的状态。

#### B-Tree 优化

* 一些数据库（LMDB）不使用覆盖页和维护WAL来进行崩溃恢复，而是使用写时复制方案。

* 保存键的缩略信息，而不是完整的键，这样可以节省页空间。
* 相邻叶子页可以按顺序保存在磁盘上。但是相比之下，LSM-Tree在合并过程中一次重写大量存储段，更容易让那个连续的键在磁盘上相互靠近。
* 添加额外的指针到树中。例如，每个叶子页面可能会向左和向右引用其同级的兄弟页。
* B-Tree的变体如分形树，借鉴了一些日志结构的想法来减少磁盘寻道。



### B-Tree vs. LSM-Tree

根据经验，LSM-Tree通常对于写入更快而读取较慢，因为必须在不同的压缩阶段检查多个不同的数据结构和SSTable。B-Tree被认为对于读取更快。

#### LSM-Tree 的优点

* LSM-Tree 通常能够承受比 B-Tree 更高的写入吞吐量

  * 具有较低的写放大（在数据库内，由于一次数据库写入请求导致的多次磁盘写）
  * 以顺序方式写入紧凑的SSTable，而不必重写树中的多个页。

* LSM-Tree 可以支持更好的压缩。

  * 由于碎片，B-Tree存储引擎使某些磁盘空间无法使用。

    

#### LSM-Tree 的缺点

* 日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作。
  * 由于磁盘的并发资源有限，所以当磁盘执行昂贵的压缩操作时，很容易发生读写请求等待的情况。
* 磁盘的有限写入带宽需要在初始写入（记录并刷新内存表到磁盘）和后台运行的压缩线程之间所共享。
  * 数据量越大，压缩所需的磁盘带宽就越多。

#### B-Tree 的优点

* 每个键都恰好唯一对应于索引中的某个位置，而日志结构的存储引擎可能在不同的段中具有相同建的多个副本
  * 可以提供强大的事务语义



### 其他索引结构

#### 在索引中存储值

* 聚集索引
  * 在索引中直接保存行数据
  * InnoDB
* 非聚集索引
  * 仅存储索引中的数据的引用
  * MySQL
* 覆盖索引
  * 包含列的索引，在索引中保存一些表的列值。

##### 多列索引

如果需要同时查询表的多个列，就需要使用到多列索引。

* 级联索引

  * 通过将一列追加到另一列，将几个字段简单地组合成一个键（索引的定义指定字段连接的顺序）。

* 多维索引

  ```sql
  select * from restaurants where latitude > 51 AND latitude < 51.5 AND longitude > 0 AND longitude < 0.5 
  ```

  * B-Tree或LSM-Tree索引无法高效的应对这种查询。
  * 更常见的是使用专门的空间索引 （R-Tree）

#### 全文搜索和模糊索引

全文搜索引擎通常支持对一个单词的所有同义词进行查询。

在Lucene中，内存中的索引是键中的字符序列的有限状态自动机，类似字典树。这个自动机可以转换成Levenshtein自动机，支持在给定编辑距离内高效地搜索单词。

这部分内容还有非常多深挖的细节，计划在第一遍读完本书后再做后续拓展。

##### 在内存中保存所有内容

>  一些VoltDB、MemSQL和Oracle TimesTen的产品是具有关系模型的内存数据库。

内存数据库的性能优势并不是因为它们不需要从磁盘读取。即使是基于磁盘的存储引擎，也可能永远不需要从磁盘读取，因为操作系统将最近使用的磁盘缓存在内存中。实际上，内存数据库可以更快，**是因为它们避免使用写磁盘的格式对内存数据结构编码的开销**。



内存数据库提供了基于磁盘索引难以实现的某些数据类型。例如，Redis为各种数据结构（如优先级队列和集合）都提供了类似数据库的访问接口。



## 事务处理与分析处理

* 在线事务处理（OLTP）
  * 根据用户的输入插入或更新记录。因为这些应用程序是交互式的。
  * OLTP要求高度可用，处理事务时延迟足够低。
* 在线分析处理（OLAP）
  * 为了区分使用数据库与事务处理的模式。

现在的趋势是，放弃使用OLTP系统用于分析目的，而是在单独的数据库上运行分析。这个单独的数据库被称为**数据仓库**。



### 数据仓库

> 数据仓库就是面向主题的（Subject-Oriented ）、集成的（Integrated）、非易失的（Non-Volatile）和时变的（Time-Variant ）数据集合，用以支持管理决策 。

现在国内最常用的是一款基于Hadoop的开源数据仓库 **Hive**，可以对存储在HDFS上的文件数据集进行查询和分析处理。

#### 数据仓库的特点

* 主题性
  * 数据仓库是围绕一个主题进行获取数据和分析数据，以此来满足数据分析的需求。
* 集成性
  * 要整合成最终的数据集合，需要对数据进行抽取、清洗、转换的过程。
* 稳定性
  * 数据仓库不允许对数据进行修改，只能进行查询和分析。
* 及时性
  * 数据仓库一定要获取最新的数据，这样数据分析出来的结果才是有效的。



#### 数据仓库如何集成不同数据源

{% asset_img 数据仓库和简化的ETL过程.png 数据仓库和简化的ETL过程 %}

将数据导入数据仓库的过程称为提取-转换-加载（Extract-Transform-Load, ETL）。

* Extract
  * 读取数据
* Transform
  * 把数据转换成需要的维度和格式，同时包含数据清洗，清洗掉一些噪音数据。
* Load
  * 把数据加载到目标仓库以供分析使用



使用单独的数据仓库而不是直接查询OLTP系统进行分析，很大的优势在于数据仓库可以针对分析访问模式进行优化。



#### OLTP数据库和数据仓库之间的差异



### 星型与雪花型分析模式

#### 星型模式

模式的中心是一个所谓的**事实表**。事实表的每一行表示在特定时间发生的事件。事实表中的列是属性，其他列可能会引用其他表的外键，称为**维度表**。

> 由于事实表中的每一行都代表一个事件，维度通常代表事件的对象（who）、什么（what）、地点（where）、时间（when）、方法（how）以及原因（why）。

事实表位于中间，被一系列维度表包围。

{% asset_img 星型模式.png 星型模式 %}



#### 雪花模式

维度进一步细分为子空间，每一行都可以再次引用品牌和类别作为外键，而不是将其作为字符串直接存储在表中。

{% asset_img 雪花型模式.png 雪花型模式 %}



## 列式储存

我们将首先关注事实表的存储。

> 面向行存储：来自表的一行所有值彼此相邻存储。
>
> 面向列存储：将每列中的所有值存储在一起。

因为我们在查询的时候通常只会需要某几个字段，显然使用列存储是一个更为优化的办法。

### 列压缩

#### 位图编码

现在可以使用n个不同值的列，并将其转换为n个单独的位图：一个位图对应每个不同的值，一个位对应一行。如果行具有该值，该位为1，否则为0。

{% asset_img 压缩的位图索引存储单列.png 压缩的位图索引存储单列 %}

#### 内存带宽和矢量化处理

* 内存带宽
  * 如何高效地将内存的带宽用于CPU缓存，避免分支错误预测和CPU指令处理流水线中的气泡，并利用现代CPU中的单指令多数据指令。
* 矢量化处理
  * 列压缩使得列中更多的行可以加载到L1缓存。

### 列存储中的排序

* 可以基于常见查询的知识来选择要排序表的列。

* 排序可以帮忙进一步压缩列
  * 如果主排序列上没有很多不同的值，在排序后，会出现一个非常长的序列，其中相同的值在一行中重复多次。

### 列存储的写操作

面向列的存储、压缩和排序都非常有助于加速读取查询，但是可以使用**LSM-Tree**。

> 所有的写入首先进入内存存储区，将其添加到已排序的结构中，接着再准备写入磁盘。当累积了足够的写入时，它们将与磁盘上的列文件合并，并批量写入新文件。





## 聚合：数据立方体与物化视图

如果许多不同查询使用相同的聚合，每次都处理原始数据将非常浪费

### 物化视图

> 一个类似表的对象，其内容是一些查询的结果。

当底层数据发生变化时，物化视图也需要随之更新，因为它是数据的非规范化副本。

### 数据立方体

物化视图一种特殊情况。它是由不同维度分组的聚合网络。

{% asset_img 数据立方体.png 数据立方体 %}

* 优点
  * 某些查询会很快，因为已经被预先计算出来了。

* 缺点
  * 缺乏像查原始数据那样的灵活性。



## 小结

存储引擎分为两大类：**针对事务处理（OLTP）优化的结构**和**针对分析型（OLAP）的优化结构**。

* OLTP
  * OLTP通常面向用户，磁盘寻道时间往往是瓶颈。
  * 有两个主要流派的存储引擎
    * 日志结构流派
    * 原地更新流派

* OLAP
  * OLAP主要由业务分析师用，磁盘带宽通常是瓶颈，可以通过面向列的存储来解决。
  * 当查询需要在大量行中顺序扫描时，索引的关联性就会显著降低。相反，最重要的是非常紧凑地编码数据，以尽量减少磁盘读取的数据量。



# 第四章 数据编码与演化



## 数据编码格式

1. 在内存中，数据保存在对象、结构体、列表、数组、哈希表和树等结构中。这些数据结构针对CPU的高效访问和操作进行了优化（通常使用指针）。
2. 将数据写入文件或通过网络发送时，必须将其编码为某种自包含的字节序列（例如JSON文档）。

> 从内存中的表示到字节序列的转化称为编码（序列化），相反的过程称为解码（反序列化）。



### JSON、XML与二进制变体

这些编码都有一定的缺点

* 在XML和CSV中，无法区分数字和碰巧由数字组成的字符串。
* JSON区分字符串和数字，但不区分整数和浮点数，并且不指定精度。
* JSON和XML对Unicode字符串有很好的支持，但是它们不支持二进制字符串。
* 由于数据的正确解释取决于模式中的信息，因此不使用XML/JSON架构的应用程序可能不得不硬编码适当的编码/解码逻辑。
* CSV没有任何模式，因此应用程序需要定义每行和每列的含义。



#### 二进制编码

JSON不像XML那么冗长，但与二进制格式相比，两者仍然占用大量空间。

```json
{
  "userName": "Martin",
  "favoriteNumber": 1337,
  "interests": ["daydreaming", "hacking"]
}
```

{% asset_img 二进制编码.png 二进制编码 %}



### Thrift与Protocol Buffers

接下来介绍的是模式（schemas）

#### Thrift

```thrift
struct Person {
	1: required string       userName,
	2: optional i64          favoriteNumber,
	3: optional list<string> interests
}
```

Thrift有两种不同的二进制编码格式：BinaryProtocol和CompactProtocol

##### BinaryProtocol

{% asset_img BinaryProtocol.png BinaryProtocol %}

最大的区别是没有字段名。相反，编码数据包含数字类型的字段标签。

##### CompactProtocol

{% asset_img CompactProtocol.png CompactProtocol %}

* 将字段类型和标签号打包到单字节中，并使用可变长度整数来实现。
* 对数字1337，不使用全部8字节，而是使用两个字节进行编码。每个字节的最高位用来指示是否还有更多的字节。

#### Protocol Buffers

```protobuf
message Person {
	required string user_name      = 1;
	optional int64 favorite_number = 2;
	repeated string interests      = 3;
}
```

{% asset_img ProtocolBuffers.png ProtocolBuffers %}



> 在前面所示的模式中，每个字段被标记为required或optional，但这对字段如何编码没有任何影响。区别在于，如果字段设置了required，但字段未填充，则运行时检查将出现失败。



#### 字段标签和模式演化

为了保持向后兼容性，在模式的初始部署之后添加的每个字段都必须是可选的或具有默认值。

为了保持向前兼容性，只能删除可选的字段（必填字段永远不能被删除）。

#### 数据类型和模式演化

Protocal Buffers 没有列表或数组数据类型，而是有字段的重复标记（repeated）。对于重复字段，表示同一个字段标签只是简单的多次出现在记录中。可以将可选（单值）字段更改为重复（多值）字段。

读取旧数据的新代码会看到一个包含零个或一个元素的列表。

读取新数据的旧代码只能看到列表的最后一个元素。



### Avro

TODO

### 模式（schema）的优点

Protocal Buffers, Thrift和Avro都使用了模式来描述二进制编码格式。



1. 可以比各种“二进制JSON”变体更紧凑（可以省略编码数据中的变量名）。
2. 模式是一种有价值的文档形式（而手动维护文档的成本是巨大的）。
3. 可以向前兼容和向后兼容。
4. 可以在编译时进行类型检查。



## 数据流模式

这里我们将探讨一些最常见的进程间数据流动的方式：

### 基于数据库的数据流

> 在数据库中，写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。

由于可能存在新旧不同版本的进程对数据库进行编码或者解码，数据库需要向前或者向后兼容。

#### 归档存储

数据传储通常使用最新的模式进行编码，即使源数据库中的原始编码包含了不同时代的各种模式版本。

### 基于服务的数据流：REST和RPC

客户端和服务器。服务器通过网络公开API，客户端可以连接到服务器以向该API发出请求。服务器公开的API称为**server**。

* web浏览器
  * 发出GET请求来下载HTML, CSS, JavaScript, 图像
  * 发出POST请求提交数据到服务器
* 移动设备或桌面计算机上运行的本地应用程序
  * 服务器的响应通常是便于客户端应用程序进一步处理的编码数据（如JSON）
* 服务器本身可以是另一项服务的客户端
  * 微服务体系架构
    * 通过使服务可独立部署和演化，让应用程序更易于更改和维护。

#### 网络服务

> 当HTTP被用作与服务通信的底层协议时，它被称为Web服务。

##### REST

REST不是一种协议，而是一个基于HTTP原则的设计理念。

* 强调简单的数据格式
* 使用URL来标识资源
* 使用HTTP功能进行缓存控制、身份验证和内容类型协商。



> 根据REST原则所设计的API称为RESTful

##### SOAP

基于XML的协议，用于发出网络API请求。

#### 远程过程调用（RPC）的问题

* 本地函数调用是可预测的，并且成功或失败仅取决于控制的参数。网络请求是不可预测的：请求或响应可能由于网络问题而丢失，或者远程计算机可能速度慢或不可用。
* 本地函数要么返回一个结果，要么抛出一个异常。网络请求有另一个可能：由于超时，它返回时可能没有结果。
* 重试失败的网络请求，可能会发生请求实际上已经完成，只是响应丢失的情况。需要在协议中建立重复数据消除（幂等性）机制
* 调用本地函数时，通常需要大致相同的时间来执行。网络请求比函数调用要慢得多，而且期延迟也有很大的变化。
* 调用本地函数时，可以高效地将引用传递给本地内存中的对象。当发出网络请求时，所有这些参数都需要被编码称可以通过网络发送的字节序列。
* 客户端和服务端可以用不同的编程语言来实现，所以RPC框架必须将数据类型从一种语言转换成另一语言。



#### RPC的发展方向

REST似乎是公共API的主流风格。RPC框架主要侧重于同一组织内多项服务之间的请求，通常发生在统一数据中心内。



#### RPC的数据编码和演化

> 重要的是可以独立地更改和部署RPC客户端和服务器。

可以假定所有的服务器都先更新，其次再是客户端。因此只需要在请求上具有向后兼容性，而在响应上具有向前兼容性即可



关于API版本管理暂时没有统一的方案

* 对于RESTFUL API，常用的方法是在URL或HTTP Accept头中使用版本号。（目前我在字节实习所用的一种方式）
* 对于使用API密钥来表示特定客户端的服务，另一种选择是将客户端请求的API版本存储在服务器上，并允许通过单独的管理接口更新该本本选项。

### 基于消息传递的数据流

RPC和数据库之间的异步消息传递系统。不是通过直接的网络连接发送消息，而是通过称为消息代理（消息队列，或面向消息的中间件）的中介发送的，该中介会暂存消息。

#### 消息代理

优点：

* 可以充当缓冲区，从而提高系统的可靠性。
* 可以自动将消息重新发送到崩溃的进程，防止消息丢失。
* 避免了发送方需要知道接收方的IP地址和端口号。
* 支持将一条消息发送给多个接收方。
* 在逻辑上将发送方与接收方分离。

消息传递通信通常是单向的。



使用方式：

1. 一个进程向指定的队列或主题发送消息。
2. 代理确保消息被传递给队列或主题的一个或多个消费者或订阅者。
3. 在同一主题上可以有许多生产者和许多消费者。



#### 分布式Actor框架

每个Actor通常代表一个客户端或实体，它可能具有某些本地状态（不与其他任何Actor共享），并且它通过发送和接收异步消息与其他Actor通信。





## 小结

许多服务需要支持滚动升级，即每次将新版本的服务逐步部署到几个节点，而不是同时部署到所有节点。因此，在系统内流动的所有数据都以提供向后兼容性和向前兼容性的方式进行编码。



数据流的几种模型

* 数据库，其中写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。
* RPC和REST API，其中客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应进行解码。
* 异步消息传递（使用消息代理或Actor），节点之间通过互相发送消息进行通信，消息由发送者编码并由接受者解码。



























