---
title: Linux中的IO
date: 2020-08-30 13:53:13
tags:
---


基于面试的时候，碰到了很多与 Linux 有关的话题，对这方面一直了解不够深。本文讨论的背景是network IO。
# 概念说明
在讨论之前，我们先需要明确几个基本的概念
## 用户空间和内核空间
对 32 位操作系统而言，它的寻址空间（虚拟地址空间，或叫线性地址空间）为 4G（2的32次方）。也就是说一个进程的最大地址空间为 4G。操作系统的核心是内核(kernel)，它独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证内核的安全，现在的操作系统一般都强制用户进程不能直接操作内核。具体的实现方式基本都是由操作系统将虚拟地址空间划分为两部分，一部分为内核空间，另一部分为用户空间。针对 Linux 操作系统而言，最高的 1G 字节(从虚拟地址 0xC0000000 到 0xFFFFFFFF)由内核使用，称为内核空间。而较低的 3G 字节(从虚拟地址 0x00000000 到 0xBFFFFFFF)由各个进程使用，称为用户空间。

每个进程的4G地址空间中，最高1G都是一样的，即内核空间，剩下3G归进程使用。最高1G的内核空间是被所有<b>进程</b>共享的。

{% asset_img 用户空间和内核空间.png 用户空间和内核空间 %}

### 为什么区分内核空间和用户空间
* CPU将指令分为特权指令和非特权指令，因为有的指令是非常危险的，如果错用，将导致系统崩溃。
* 对于危险的指令，只允许操作系统及其相关模块使用，普通应用程序只能使用那些不会造成灾难的指令

### 内核态和用户态
当进程运行在内核空间时就处于内核状态，而进程运行在用户空间时则处于用户态。
* 在内核态下，进程运行在内核地址空间，此时CPU可以执行任何指令。运行的代码也不受限制，可以自由访问任何有效地址，也可以直接进行端口访问。
* 在用户态下，进程运行在用户地址空间中，被执行的代码要受到 CPU 的诸多检查，它们只能访问映射其地址空间的页表项中规定的在用户态下可访问页面的虚拟地址，且只能对任务状态段(TSS)中 I/O 许可位图(I/O Permission Bitmap)中规定的可访问端口进行直接访问。

### 参考文献
https://www.cnblogs.com/sparkdev/p/8410350.html

## 进程切换
为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这就被称为进程切换。

从一个进程的运行转到另一个进程上进行，整个过程经历了以下的变化
1. 保存处理机上下文
2. 更新PCB信息
3. 把进程的PCB移入相应的队列，如就绪、在某事件阻塞队列。
4. 选择另一个进程执行，并更新其PCB
5. 更新内存管理的数据结构
6. 恢复处理机上下文

tips: PCB (Process Control Block) 为了描述控制进程的运行，系统中存放进程的管理和控制信息的数据结构。是进程实体的一部分，是操作系统中最重要的记录性数据结构。

## 进程的阻塞
正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种<b>主动</b>行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。

## 文件的描述符
文件描述符(File Descriptor)是一个用于表述指向文件的引用的抽象化概念。实际上，他是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。

## 缓存 I/O
缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。

### 缺点
数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。

# IO 模式
接下来我们详细介绍一下IO的几种模式，对于一次IO的访问，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。
1. 用户进程空间 <--> 内核空间
2. 内核空间 <--> 设备空间

* Linux 中进程无法直接操作I/O设备，其必须通过系统调用请求kernel来协助完成I/O动作
* 内核会为每个I/O设备维护一个缓冲区
* 对于一个输入操作来说，进程IO系统调用后，内核会先看缓冲区中有没有相应的缓存数据，没有的话再到设备中读取，因为设备IO一般速度较慢，需要等待；内核缓冲区有数据则直接复制到进程空间。
    * 等待网络数据到达网卡 -> 读取到内核缓冲区，准备好数据
    * 从内核缓冲区复制数据到进程空间

由于这两个阶段的存在，Linux系统产生下面五种网络模式的方案
## 阻塞 I/O
在 Linux 中，默认情况下所有的socket都使用的阻塞，一个典型的读流程是这样的：

{% asset_img 阻塞I/O.png 阻塞I/O %}

进程发起IO系统调用后，进程被阻塞，转到内核空间处理，整个IO处理完毕后返回进程。操作成功则进程获取数据。

> blocking IO 的特点就是在 IO 执行的两个阶段都被 block 了

1. 应用: 阻塞socket, Java BIO
2. 特点

    * 进程阻塞不消耗CPU资源，及时响应每个操作
    * 实现难度低，开发比较容易
    * 适用并发量小的网络应用开发
    * 不适用并发量大的应用: 因为一个请求IO会阻塞线程，得为每请求分配一个处理进程(线程)以及时响应，系统开销大。

## 非阻塞 I/O
在Linux 中，可以通过设置 socket 使其变为 non-blocking. 当对一个 non-blocking socket执行读操作时，流程是这样的：

{% asset_img 非阻塞I/O.png 非阻塞I/O %}

进程发起IO系统调用后，如果内核缓冲区没有数据，需要到IO设备中读取，进程返回一个错误而不会被阻塞。进程发起IO系统调用后，如果内核缓冲区有数据，内核就会把数据返回进程。

1. 应用: socket的非阻塞方式
2. 特点

    * 进程轮询调用消耗CPU资源
    * 实现难度低，开发应用相对阻塞IO模式较难


## I/O 多路复用
这里就涉及到我们说的 ```select```, ```poll```, ```epoll```. 他们都是IO多路复用机制，I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪(一般是读就绪或者写就绪)，能够通知程序进行相应的读写操作。但```select```, ```poll```, ```epoll```本质上都是同步IO, 因为它们都需要在读写时间就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间



**select**/**poll**的好处在于单个process就可以同时处理多个网络连接的I/O. 它的原理

{% asset_img I/O复用.png I/O复用 %}

上面的图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (```select``` 和 ```recvfrom```)，而blocking IO只调用了一个system call (```recvfrom```)。但是，用select的优势在于它可以同时处理多个connection。

### select
* select 调用是内核级别的，```select```轮询相对非阻塞区别在于：```select``` 可以等待多个socket, 能实现同时对多个 IO 端口进行监听，当其中任何一个socket的数据准备好了，就能返回进行可读，然后进程再进行```recvform```系统调用，将数据由内核拷贝到用户进程，这个过程是阻塞的。
* ```select```或者```poll``` 调用之后，会阻塞进程。与blocking IO阻塞的区别在于，此时的select不是等到socket数据全部到达再处理，而是有了一部分数据就会调用用户进程来处理。```select```的优势在于它可以同时处理多个connection

#### 具体流程
1. 当用户进程调用 select, 那么整个进程会被 block. 
2. 同时, kernel会监视所有select负责的socket, 当任何一个socket中的数据准备好了, select就会返回。
3. 这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。

在 I/O 编程中，当需要同时处理多个客户端接入请求时，可以利用多线程或者 I/O 多路复用技术进行处理。I/O 多路复用技术通过把多个 I/O 的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。

#### 优势
* I/O多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源。


#### 具体实现

```C
int select(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```


一共 ```select``` 函数监视的文件描述符分3类，分别是```writefds```、```readfds```、和```exceptfds```。调用后```select```函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当```select```函数返回后，可以 通过遍历```fdset```，来找到就绪的描述符。


注册IO、阻塞扫描，监听的IO最大连接数不能多于FD_SIZE

### poll 
原理和select相似，没有数量限制，但IO数量大 扫描线性性能下降

#### 具体实现

```C
int poll (struct pollfd *fds, unsigned int nfds, int timeout);
```

不同于```select```使用三个位置来表示三个fdset的方式，```poll```使用一个pollfd的指针来实现。

```C
struct pollfd {
    int fd;        // file description
    short events;  // requested events to watch
    short revents; // returned events witnessed 
}
```

pollfd结构包含了要监视的event和发生的event，不再使用```select``` "参数-值" 传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和```select```函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。


### epoll
事件驱动不阻塞，mmap实现内核与用户空间的消息传递，数量很大

// TODO


### 参考文献
https://www.jianshu.com/p/486b0965c296


## 信号驱动 I/O
这个目前并不常见
## 异步 I/O
相比于同步IO，异步IO 不是顺序执行。用户进程进行```aio_read```系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户进程就可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。

{% asset_img 异步I/O.png 异步I/O %}


# 参考文献
https://segmentfault.com/a/1190000003063859