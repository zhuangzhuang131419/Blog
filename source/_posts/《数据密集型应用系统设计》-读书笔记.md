---
title: 《数据密集型应用系统设计》- 读书笔记
date: 2021-01-13 10:05:51
tags: 读书笔记
categories: 分布式系统
---

[TOC]



# 第二章 数据模型与查询语言

# 第三章 数据存储与检索

## 数据库核心：数据结构

适当的索引可以加速度取查询，但每个索引都会减慢写速度

### 哈希索引

假设数据存储全部采用追加式文件组成。

> 保存内存中的hash map, 把每个键一一映射到数据文件中特定的字节偏移量，这样就可以找到每个值的位置。

Bitcask （Riak 中的默认存储引擎）就是采用哈希索引的。它非常适合每个键的值频繁更新的场景。



如何避免最终用尽磁盘空间？

> 我们可以将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。然后可以在这些段上执行压缩，在日志中丢弃重复的键，并且只保留每个键最近的更新。



#### 需要考虑的问题

* 文件格式
  * csv 不是日志的最佳格式，应该使用二进制的格式，首先以字节为单位来记录字符串的长度，之后再跟上原始字符串。
* 删除记录
  * 如果要删除一个键和它关联的记录，在数据文件中追加一个tag。合并日志的时候，一旦发现tag，则会丢弃这个已经删除键的值。
* 崩溃恢复
  * 因为hash map是存在内存中的，数据库重新启动之后会丢失。Bitcask 通过将每个段的hash map的快照存储在磁盘上，可以更快的加载到内存中，以此加快恢复速度。
* 部分写入的记录
  * Bitcask 文件包括校验值，这样可以发现损坏部分并丢弃。
* 并发控制
  * 因为写入以严格的先后顺序追加到日志中，通常的实现选择是只有一个写线程。数据文件段是追加的，并且是不可变的，所以他们可以被多个线程同时读取。

#### 局限性

* 因为hash map 必须放在内存中，如果一旦有大量的键，就需要在磁盘维护hash map，这会导致整体的性能下降。
* 区间查询效率不高。

### SSTables和LSM-Tree

#### SSTables

> 要求每个存储段的key-value对的顺序按键排序。要求每个键在合并的段文件中只能出现一次。

>SSTable 是一个**持久化的、有序的、不可变的**映射表（map），其中的**键和值都可以 是任意字节字符串**。它提供了按 key 查询和对指定的 key range 进行遍历的操作。

SSTable相比哈希索引，具有优点：

* 合并段更加简单高效，即使文件大于可用内存
* 在文件中查找特定的键时，不再需要在内存中保存所有键的索引。仍然需要一个内存索引来记录某些键的偏移，但它可以是稀疏的。

{% asset_img SSTable及其内存中的索引.png SSTable及其内存中的索引 %}



##### 从SSTables到LSM-Tree

> 基于合并和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎。

LSM Tree的树节点可以分为两种，保存在内存中的称之为MemTable， 保存在磁盘上的称之为SSTable。



##### 构建和维护SSTables

* 当写入时，将其添加到内存中的平衡树数据结构中。这个内存中的树有时被称为内存表。
* 当内存表大于某个阈值时，将其作为SSTable文件写入磁盘。由于树已经维护了按键排序的key-value对，写磁盘可以比较高效。新的SSTable文件成为数据库的最新部分。当SSTable写磁盘的同时，写入可以继续添加到一个新的内存表实例。
* 处理读请求时，首先尝试在内存表中查找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件......
* 后台进程周期性的执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值。

LevelDB 和 RocksDB 使用的就是上面这段算法。



不同的策略会影响甚至决定SSTables压缩和合并时的具体顺序和时机。

* LevelDB和RocksDB使用分层压缩
  * 键的范围分裂成多个更小的SSTables，旧数据被移动到单独的“层级”。
* HBase使用大小分级
  * 较新的和较小的SSTables 被连续合并到较旧和较大的SSTables
* Cassandra则同时支持这两种压缩。



LSM-Tree 的基本思想：

> 保存在后台合并的一系列SSTable

[LSM-Tree初探](https://zhuangzhuang131419.github.io/2021/01/18/LSM-Tree%E5%88%9D%E6%8E%A2/)

### B-Tree

B-Tree 已经比较熟悉它的基本原理了，这里讲一些新的收获。

> B-Tree 将数据库分解成固定大小的块或页，页是内部读/写的最小单元。每个页面都可以使用地址或位置进行标识，不过是指向磁盘地址，而不是内存。



#### B-Tree 可靠

* 预写日志（write-ahead log, WAL）
  * 这是一个仅支持追加修改的文件，每个B-Tree的修改必须先更新 WAL 然后再修改树本身的页。当数据库在崩溃后需要恢复时，该日志用于将B-Tree恢复到最近一直的状态。

* 原地更新页
  * 如果多个线程要同时访问B-Tree，则需要注意并发控制，否则线程可能会看到树处于不一致的状态。

#### B-Tree 优化

* 一些数据库（LMDB）不使用覆盖页和维护WAL来进行崩溃恢复，而是使用写时复制方案。

* 保存键的缩略信息，而不是完整的键，这样可以节省页空间。
* 相邻叶子页可以按顺序保存在磁盘上。但是相比之下，LSM-Tree在合并过程中一次重写大量存储段，更容易让那个连续的键在磁盘上相互靠近。
* 添加额外的指针到树中。例如，每个叶子页面可能会向左和向右引用其同级的兄弟页。
* B-Tree的变体如分形树，借鉴了一些日志结构的想法来减少磁盘寻道。



### B-Tree vs. LSM-Tree

根据经验，LSM-Tree通常对于写入更快而读取较慢，因为必须在不同的压缩阶段检查多个不同的数据结构和SSTable。B-Tree被认为对于读取更快。

#### LSM-Tree 的优点

* LSM-Tree 通常能够承受比 B-Tree 更高的写入吞吐量

  * 具有较低的写放大（在数据库内，由于一次数据库写入请求导致的多次磁盘写）
  * 以顺序方式写入紧凑的SSTable，而不必重写树中的多个页。

* LSM-Tree 可以支持更好的压缩。

  * 由于碎片，B-Tree存储引擎使某些磁盘空间无法使用。

    

#### LSM-Tree 的缺点

* 日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作。
  * 由于磁盘的并发资源有限，所以当磁盘执行昂贵的压缩操作时，很容易发生读写请求等待的情况。
* 磁盘的有限写入带宽需要在初始写入（记录并刷新内存表到磁盘）和后台运行的压缩线程之间所共享。
  * 数据量越大，压缩所需的磁盘带宽就越多。

#### B-Tree 的优点

* 每个键都恰好唯一对应于索引中的某个位置，而日志结构的存储引擎可能在不同的段中具有相同建的多个副本
  * 可以提供强大的事务语义



### 其他索引结构

#### 在索引中存储值

* 聚集索引
  * 在索引中直接保存行数据
  * InnoDB
* 非聚集索引
  * 仅存储索引中的数据的引用
  * MySQL
* 覆盖索引
  * 包含列的索引，在索引中保存一些表的列值。

##### 多列索引

如果需要同时查询表的多个列，就需要使用到多列索引。

* 级联索引

  * 通过将一列追加到另一列，将几个字段简单地组合成一个键（索引的定义指定字段连接的顺序）。

* 多维索引

  ```sql
  select * from restaurants where latitude > 51 AND latitude < 51.5 AND longitude > 0 AND longitude < 0.5 
  ```

  * B-Tree或LSM-Tree索引无法高效的应对这种查询。
  * 更常见的是使用专门的空间索引 （R-Tree）

#### 全文搜索和模糊索引

全文搜索引擎通常支持对一个单词的所有同义词进行查询。

在Lucene中，内存中的索引是键中的字符序列的有限状态自动机，类似字典树。这个自动机可以转换成Levenshtein自动机，支持在给定编辑距离内高效地搜索单词。

这部分内容还有非常多深挖的细节，计划在第一遍读完本书后再做后续拓展。

##### 在内存中保存所有内容

>  一些VoltDB、MemSQL和Oracle TimesTen的产品是具有关系模型的内存数据库。

内存数据库的性能优势并不是因为它们不需要从磁盘读取。即使是基于磁盘的存储引擎，也可能永远不需要从磁盘读取，因为操作系统将最近使用的磁盘缓存在内存中。实际上，内存数据库可以更快，**是因为它们避免使用写磁盘的格式对内存数据结构编码的开销**。



内存数据库提供了基于磁盘索引难以实现的某些数据类型。例如，Redis为各种数据结构（如优先级队列和集合）都提供了类似数据库的访问接口。



## 事务处理与分析处理

* 在线事务处理（OLTP）
  * 根据用户的输入插入或更新记录。因为这些应用程序是交互式的。
  * OLTP要求高度可用，处理事务时延迟足够低。
* 在线分析处理（OLAP）
  * 为了区分使用数据库与事务处理的模式。

现在的趋势是，放弃使用OLTP系统用于分析目的，而是在单独的数据库上运行分析。这个单独的数据库被称为**数据仓库**。



### 数据仓库

> 数据仓库就是面向主题的（Subject-Oriented ）、集成的（Integrated）、非易失的（Non-Volatile）和时变的（Time-Variant ）数据集合，用以支持管理决策 。

现在国内最常用的是一款基于Hadoop的开源数据仓库 **Hive**，可以对存储在HDFS上的文件数据集进行查询和分析处理。

#### 数据仓库的特点

* 主题性
  * 数据仓库是围绕一个主题进行获取数据和分析数据，以此来满足数据分析的需求。
* 集成性
  * 要整合成最终的数据集合，需要对数据进行抽取、清洗、转换的过程。
* 稳定性
  * 数据仓库不允许对数据进行修改，只能进行查询和分析。
* 及时性
  * 数据仓库一定要获取最新的数据，这样数据分析出来的结果才是有效的。



#### 数据仓库如何集成不同数据源

{% asset_img 数据仓库和简化的ETL过程.png 数据仓库和简化的ETL过程 %}

将数据导入数据仓库的过程称为提取-转换-加载（Extract-Transform-Load, ETL）。

* Extract
  * 读取数据
* Transform
  * 把数据转换成需要的维度和格式，同时包含数据清洗，清洗掉一些噪音数据。
* Load
  * 把数据加载到目标仓库以供分析使用



使用单独的数据仓库而不是直接查询OLTP系统进行分析，很大的优势在于数据仓库可以针对分析访问模式进行优化。



#### OLTP数据库和数据仓库之间的差异



### 星型与雪花型分析模式

#### 星型模式

模式的中心是一个所谓的**事实表**。事实表的每一行表示在特定时间发生的事件。事实表中的列是属性，其他列可能会引用其他表的外键，称为**维度表**。

> 由于事实表中的每一行都代表一个事件，维度通常代表事件的对象（who）、什么（what）、地点（where）、时间（when）、方法（how）以及原因（why）。

事实表位于中间，被一系列维度表包围。

{% asset_img 星型模式.png 星型模式 %}



#### 雪花模式

维度进一步细分为子空间，每一行都可以再次引用品牌和类别作为外键，而不是将其作为字符串直接存储在表中。

{% asset_img 雪花型模式.png 雪花型模式 %}



## 列式储存

我们将首先关注事实表的存储。

> 面向行存储：来自表的一行所有值彼此相邻存储。
>
> 面向列存储：将每列中的所有值存储在一起。

因为我们在查询的时候通常只会需要某几个字段，显然使用列存储是一个更为优化的办法。

### 列压缩

#### 位图编码

现在可以使用n个不同值的列，并将其转换为n个单独的位图：一个位图对应每个不同的值，一个位对应一行。如果行具有该值，该位为1，否则为0。

{% asset_img 压缩的位图索引存储单列.png 压缩的位图索引存储单列 %}

#### 内存带宽和矢量化处理

* 内存带宽
  * 如何高效地将内存的带宽用于CPU缓存，避免分支错误预测和CPU指令处理流水线中的气泡，并利用现代CPU中的单指令多数据指令。
* 矢量化处理
  * 列压缩使得列中更多的行可以加载到L1缓存。

### 列存储中的排序

* 可以基于常见查询的知识来选择要排序表的列。

* 排序可以帮忙进一步压缩列
  * 如果主排序列上没有很多不同的值，在排序后，会出现一个非常长的序列，其中相同的值在一行中重复多次。

### 列存储的写操作

面向列的存储、压缩和排序都非常有助于加速读取查询，但是可以使用**LSM-Tree**。

> 所有的写入首先进入内存存储区，将其添加到已排序的结构中，接着再准备写入磁盘。当累积了足够的写入时，它们将与磁盘上的列文件合并，并批量写入新文件。





## 聚合：数据立方体与物化视图

如果许多不同查询使用相同的聚合，每次都处理原始数据将非常浪费

### 物化视图

> 一个类似表的对象，其内容是一些查询的结果。

当底层数据发生变化时，物化视图也需要随之更新，因为它是数据的非规范化副本。

### 数据立方体

物化视图一种特殊情况。它是由不同维度分组的聚合网络。

{% asset_img 数据立方体.png 数据立方体 %}

* 优点
  * 某些查询会很快，因为已经被预先计算出来了。

* 缺点
  * 缺乏像查原始数据那样的灵活性。



## 小结

存储引擎分为两大类：**针对事务处理（OLTP）优化的结构**和**针对分析型（OLAP）的优化结构**。

* OLTP
  * OLTP通常面向用户，磁盘寻道时间往往是瓶颈。
  * 有两个主要流派的存储引擎
    * 日志结构流派
    * 原地更新流派

* OLAP
  * OLAP主要由业务分析师用，磁盘带宽通常是瓶颈，可以通过面向列的存储来解决。
  * 当查询需要在大量行中顺序扫描时，索引的关联性就会显著降低。相反，最重要的是非常紧凑地编码数据，以尽量减少磁盘读取的数据量。



# 第四章 数据编码与演化



## 数据编码格式

1. 在内存中，数据保存在对象、结构体、列表、数组、哈希表和树等结构中。这些数据结构针对CPU的高效访问和操作进行了优化（通常使用指针）。
2. 将数据写入文件或通过网络发送时，必须将其编码为某种自包含的字节序列（例如JSON文档）。

> 从内存中的表示到字节序列的转化称为编码（序列化），相反的过程称为解码（反序列化）。



### JSON、XML与二进制变体

这些编码都有一定的缺点

* 在XML和CSV中，无法区分数字和碰巧由数字组成的字符串。
* JSON区分字符串和数字，但不区分整数和浮点数，并且不指定精度。
* JSON和XML对Unicode字符串有很好的支持，但是它们不支持二进制字符串。
* 由于数据的正确解释取决于模式中的信息，因此不使用XML/JSON架构的应用程序可能不得不硬编码适当的编码/解码逻辑。
* CSV没有任何模式，因此应用程序需要定义每行和每列的含义。



#### 二进制编码

JSON不像XML那么冗长，但与二进制格式相比，两者仍然占用大量空间。

```json
{
  "userName": "Martin",
  "favoriteNumber": 1337,
  "interests": ["daydreaming", "hacking"]
}
```

{% asset_img 二进制编码.png 二进制编码 %}



### Thrift与Protocol Buffers

#### Thrift

```thrift
struct Person {
	1: required string       userName,
	2: optional i64          favoriteNumber,
	3: optional list<string> interests
}
```

Thrift有两种不同的二进制编码格式：BinaryProtocol和CompactProtocol

##### BinaryProtocol

{% asset_img BinaryProtocol.png BinaryProtocol %}

最大的区别是没有字段名。相反，编码数据包含数字类型的字段标签。

##### CompactProtocol

{% asset_img CompactProtocol.png CompactProtocol %}

* 将字段类型和标签号打包到单字节中，并使用可变长度整数来实现。
* 对数字1337，不使用全部8字节，而是使用两个字节进行编码。每个字节的最高位用来指示是否还有更多的字节。

#### Protocol Buffers

```protobuf
message Person {
	required string user_name      = 1;
	optional int64 favorite_number = 2;
	repeated string interests      = 3;
}
```

{% asset_img ProtocolBuffers.png ProtocolBuffers %}







